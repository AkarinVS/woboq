<dec f='llvm/llvm/include/llvm/MCA/HardwareUnits/LSUnit.h' l='435' type='unsigned int'/>
<use f='llvm/llvm/include/llvm/MCA/HardwareUnits/LSUnit.h' l='446' u='w' c='_ZN4llvm3mca6LSUnitC1ERKNS_12MCSchedModelEjjb'/>
<offset>480</offset>
<doc f='llvm/llvm/include/llvm/MCA/HardwareUnits/LSUnit.h' l='397'>// This class doesn&apos;t know about the latency of a load instruction. So, it
  // conservatively/pessimistically assumes that the latency of a load opcode
  // matches the instruction latency.
  //
  // FIXME: In the absence of cache misses (i.e. L1I/L1D/iTLB/dTLB hits/misses),
  // and load/store conflicts, the latency of a load is determined by the depth
  // of the load pipeline. So, we could use field `LoadLatency` in the
  // MCSchedModel to model that latency.
  // Field `LoadLatency` often matches the so-called &apos;load-to-use&apos; latency from
  // L1D, and it usually already accounts for any extra latency due to data
  // forwarding.
  // When doing throughput analysis, `LoadLatency` is likely to
  // be a better predictor of load latency than instruction latency. This is
  // particularly true when simulating code with temporal/spatial locality of
  // memory accesses.
  // Using `LoadLatency` (instead of the instruction latency) is also expected
  // to improve the load queue allocation for long latency instructions with
  // folded memory operands (See PR39829).
  //
  // FIXME: On some processors, load/store operations are split into multiple
  // uOps. For example, X86 AMD Jaguar natively supports 128-bit data types, but
  // not 256-bit data types. So, a 256-bit load is effectively split into two
  // 128-bit loads, and each split load consumes one &apos;LoadQueue&apos; entry. For
  // simplicity, this class optimistically assumes that a load instruction only
  // consumes one entry in the LoadQueue.  Similarly, store instructions only
  // consume a single entry in the StoreQueue.
  // In future, we should reassess the quality of this design, and consider
  // alternative approaches that let instructions specify the number of
  // load/store queue entries which they consume at dispatch stage (See
  // PR39830).
  //
  // An instruction that both &apos;mayStore&apos; and &apos;HasUnmodeledSideEffects&apos; is
  // conservatively treated as a store barrier. It forces older store to be
  // executed before newer stores are issued.
  //
  // An instruction that both &apos;MayLoad&apos; and &apos;HasUnmodeledSideEffects&apos; is
  // conservatively treated as a load barrier. It forces older loads to execute
  // before newer loads are issued.</doc>
<use f='llvm/llvm/lib/MCA/HardwareUnits/LSUnit.cpp' l='86' u='r' c='_ZN4llvm3mca6LSUnit8dispatchERKNS0_7InstRefE'/>
<use f='llvm/llvm/lib/MCA/HardwareUnits/LSUnit.cpp' l='118' u='w' c='_ZN4llvm3mca6LSUnit8dispatchERKNS0_7InstRefE'/>
<use f='llvm/llvm/lib/MCA/HardwareUnits/LSUnit.cpp' l='129' u='r' c='_ZN4llvm3mca6LSUnit8dispatchERKNS0_7InstRefE'/>
<use f='llvm/llvm/lib/MCA/HardwareUnits/LSUnit.cpp' l='183' u='w' c='_ZN4llvm3mca6LSUnit8dispatchERKNS0_7InstRefE'/>
<use f='llvm/llvm/lib/MCA/HardwareUnits/LSUnit.cpp' l='190' u='r' c='_ZN4llvm3mca6LSUnit8dispatchERKNS0_7InstRefE'/>
<use f='llvm/llvm/lib/MCA/HardwareUnits/LSUnit.cpp' l='192' u='r' c='_ZN4llvm3mca6LSUnit8dispatchERKNS0_7InstRefE'/>
<use f='llvm/llvm/lib/MCA/HardwareUnits/LSUnit.cpp' l='240' u='r' c='_ZN4llvm3mca6LSUnit21onInstructionExecutedERKNS0_7InstRefE'/>
<use f='llvm/llvm/lib/MCA/HardwareUnits/LSUnit.cpp' l='241' u='w' c='_ZN4llvm3mca6LSUnit21onInstructionExecutedERKNS0_7InstRefE'/>
