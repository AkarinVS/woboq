<dec f='llvm/llvm/lib/Target/AMDGPU/SIRegisterInfo.h' l='109' type='void llvm::SIRegisterInfo::buildSGPRSpillLoadStore(MachineBasicBlock::iterator MI, int Index, int Offset, unsigned int EltSize, llvm::Register VGPR, int64_t VGPRLanes, llvm::RegScavenger * RS, bool IsLoad) const'/>
<def f='llvm/llvm/lib/Target/AMDGPU/SIRegisterInfo.cpp' l='1027' ll='1138' type='void llvm::SIRegisterInfo::buildSGPRSpillLoadStore(MachineBasicBlock::iterator MI, int Index, int Offset, unsigned int EltSize, llvm::Register VGPR, int64_t VGPRLanes, llvm::RegScavenger * RS, bool IsLoad) const'/>
<use f='llvm/llvm/lib/Target/AMDGPU/SIRegisterInfo.cpp' l='1246' u='c' c='_ZNK4llvm14SIRegisterInfo9spillSGPRENS_26MachineInstrBundleIteratorINS_12MachineInstrELb0EEEiPNS_12RegScavengerEb'/>
<use f='llvm/llvm/lib/Target/AMDGPU/SIRegisterInfo.cpp' l='1309' u='c' c='_ZNK4llvm14SIRegisterInfo11restoreSGPRENS_26MachineInstrBundleIteratorINS_12MachineInstrELb0EEEiPNS_12RegScavengerEb'/>
<doc f='llvm/llvm/lib/Target/AMDGPU/SIRegisterInfo.cpp' l='1023'>// Generate a VMEM access which loads or stores the VGPR containing an SGPR
// spill such that all the lanes set in VGPRLanes are loaded or stored.
// This generates exec mask manipulation and will use SGPRs available in MI
// or VGPR lanes in the VGPR to save and restore the exec mask.</doc>
