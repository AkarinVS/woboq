<dec f='llvm/llvm/tools/llvm-exegesis/lib/Clustering.h' l='132' type='void llvm::exegesis::InstructionBenchmarkClustering::stabilize(unsigned int NumOpcodes)'/>
<doc f='llvm/llvm/tools/llvm-exegesis/lib/Clustering.h' l='131'>// Stabilization is only needed if dbscan was used to clusterize.</doc>
<def f='llvm/llvm/tools/llvm-exegesis/lib/Clustering.cpp' l='239' ll='315' type='void llvm::exegesis::InstructionBenchmarkClustering::stabilize(unsigned int NumOpcodes)'/>
<use f='llvm/llvm/tools/llvm-exegesis/lib/Clustering.cpp' l='334' u='c' c='_ZN4llvm8exegesis30InstructionBenchmarkClustering6createERKSt6vectorINS0_20InstructionBenchmarkESaIS3_EENS1_5ModeEEmdNS_8OptionalIjEE'/>
<doc f='llvm/llvm/tools/llvm-exegesis/lib/Clustering.cpp' l='228'>// Given an instruction Opcode, we can make benchmarks (measurements) of the
// instruction characteristics/performance. Then, to facilitate further analysis
// we group the benchmarks with *similar* characteristics into clusters.
// Now, this is all not entirely deterministic. Some instructions have variable
// characteristics, depending on their arguments. And thus, if we do several
// benchmarks of the same instruction Opcode, we may end up with *different*
// performance characteristics measurements. And when we then do clustering,
// these several benchmarks of the same instruction Opcode may end up being
// clustered into *different* clusters. This is not great for further analysis.
// We shall find every opcode with benchmarks not in just one cluster, and move
// *all* the benchmarks of said Opcode into one new unstable cluster per Opcode.</doc>
