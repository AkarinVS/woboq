<def f='llvm/polly/lib/External/ppcg/gpu_group.c' l='467' ll='479'/>
<use f='llvm/polly/lib/External/ppcg/gpu_group.c' l='516' c='access_is_coalesced'/>
<use f='llvm/polly/lib/External/ppcg/gpu_group.c' l='574' c='localize_access'/>
<use f='llvm/polly/lib/External/ppcg/gpu_group.c' l='602' c='access_is_bijective'/>
<use f='llvm/polly/lib/External/ppcg/gpu_group.c' l='629' c='compute_tile_depth'/>
<use f='llvm/polly/lib/External/ppcg/gpu_group.c' l='698' c='compute_accessed_by_single_thread_depth'/>
<use f='llvm/polly/lib/External/ppcg/gpu_group.c' l='776' c='tile_set_depth'/>
<use f='llvm/polly/lib/External/ppcg/gpu_group.c' l='791' c='set_depth'/>
<use f='llvm/polly/lib/External/ppcg/gpu_group.c' l='819' c='populate_array_references'/>
<use f='llvm/polly/lib/External/ppcg/gpu_group.c' l='990' c='check_requires_unroll'/>
<use f='llvm/polly/lib/External/ppcg/gpu_group.c' l='1008' c='shared_access'/>
<use f='llvm/polly/lib/External/ppcg/gpu_group.c' l='1092' c='compute_group_bounds_core'/>
<use f='llvm/polly/lib/External/ppcg/gpu_group.c' l='1201' c='compute_group_bounds'/>
<use f='llvm/polly/lib/External/ppcg/gpu_group.c' l='1226' c='group_writes'/>
<use f='llvm/polly/lib/External/ppcg/gpu_group.c' l='1263' c='group_overlapping_writes'/>
<use f='llvm/polly/lib/External/ppcg/gpu_group.c' l='1301' c='group_depth_overlapping_writes'/>
<use f='llvm/polly/lib/External/ppcg/gpu_group.c' l='1344' c='group_common_shared_memory_tile'/>
<use f='llvm/polly/lib/External/ppcg/gpu_group.c' l='1445' c='group_array_references'/>
<use f='llvm/polly/lib/External/ppcg/gpu_group.c' l='1561' c='compute_privatization'/>
<use f='llvm/polly/lib/External/ppcg/gpu_group.c' l='1633' c='gpu_group_references'/>
<size>72</size>
<doc f='llvm/polly/lib/External/ppcg/gpu_group.c' l='436'>/* Internal data structure for gpu_group_references.
 *
 * scop represents the input scop.
 * kernel_depth is the schedule depth where the kernel launch will
 * be introduced, i.e., it is the depth of the band that is mapped
 * to blocks.
 * shared_depth is the schedule depth at which the copying to/from
 * shared memory is computed.  The copy operation may then
 * later be hoisted to a higher level.
 * thread_depth is the schedule depth where the thread mark is located,
 * i.e., it is the depth of the band that is mapped to threads and also
 * the schedule depth at which the copying to/from private memory
 * is computed.  The copy operation may then later be hoisted to
 * a higher level.
 * n_thread is the number of schedule dimensions in the band that
 * is mapped to threads.
 * privatization lives in the range of thread_sched (i.e., it is
 * of dimension thread_depth + n_thread) and encodes the mapping
 * to thread identifiers (as parameters).
 * host_sched contains the kernel_depth dimensions of the host schedule.
 * shared_sched contains the first shared_depth dimensions of the
 * kernel schedule.
 * copy_sched contains the first thread_depth dimensions of the
 * kernel schedule.
 * thread_sched contains the first (thread_depth + n_thread) dimensions
 * of the kernel schedule.
 * full_sched is a union_map representation of the entire kernel schedule.
 * The schedules are all formulated in terms of the original statement
 * instances, i.e., those that appear in the domains of the access
 * relations.
 */</doc>
