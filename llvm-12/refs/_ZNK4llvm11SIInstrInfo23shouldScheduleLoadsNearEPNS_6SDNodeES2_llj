<dec f='llvm/llvm/lib/Target/AMDGPU/SIInstrInfo.h' l='191' type='bool llvm::SIInstrInfo::shouldScheduleLoadsNear(llvm::SDNode * Load0, llvm::SDNode * Load1, int64_t Offset0, int64_t Offset1, unsigned int NumLoads) const'/>
<inh f='llvm/llvm/include/llvm/CodeGen/TargetInstrInfo.h' l='1287' c='_ZNK4llvm15TargetInstrInfo23shouldScheduleLoadsNearEPNS_6SDNodeES2_llj'/>
<def f='llvm/llvm/lib/Target/AMDGPU/SIInstrInfo.cpp' l='484' ll='494' type='bool llvm::SIInstrInfo::shouldScheduleLoadsNear(llvm::SDNode * Load0, llvm::SDNode * Load1, int64_t Offset0, int64_t Offset1, unsigned int NumLoads) const'/>
<doc f='llvm/llvm/lib/Target/AMDGPU/SIInstrInfo.cpp' l='474'>// FIXME: This behaves strangely. If, for example, you have 32 load + stores,
// the first 16 loads will be interleaved with the stores, and the next 16 will
// be clustered as expected. It should really split into 2 16 store batches.
//
// Loads are clustered until this returns false, rather than trying to schedule
// groups of stores. This also means we have to deal with saying different
// address space loads should be clustered, and ones which might cause bank
// conflicts.
//
// This might be deprecated so it might not be worth that much effort to fix.</doc>
