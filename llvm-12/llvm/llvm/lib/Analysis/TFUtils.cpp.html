<!doctype html>
<html>
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0"><title>TFUtils.cpp source code [llvm/llvm/lib/Analysis/TFUtils.cpp] - Woboq Code Browser</title>
<link rel="stylesheet" href="../../../.././data/qtcreator.css" title="QtCreator"/>
<link rel="alternate stylesheet" href="../../../.././data/kdevelop.css" title="KDevelop"/>
<script type="text/javascript" src="../../../.././data/jquery/jquery.min.js"></script>
<script type="text/javascript" src="../../../.././data/jquery/jquery-ui.min.js"></script>
<script>var file = 'llvm/llvm/lib/Analysis/TFUtils.cpp'; var root_path = '../../../..'; var data_path = '../../../.././data'; var ecma_script_api_version = 2;</script>
<script src='../../../.././data/codebrowser.js'></script>
</head>
<body><div id='header'><h1 id='breadcrumb'><span>Browse the source code of </span><a href='../../..'>llvm</a>/<a href='../..'>llvm</a>/<a href='..'>lib</a>/<a href='./'>Analysis</a>/<a href='TFUtils.cpp.html'>TFUtils.cpp</a></h1></div>
<hr/><div id='content'><table class="code">
<tr><th id="1">1</th><td><i>//===- TFUtils.cpp - tensorflow evaluation utilities ----------------------===//</i></td></tr>
<tr><th id="2">2</th><td><i>//</i></td></tr>
<tr><th id="3">3</th><td><i>//                     The LLVM Compiler Infrastructure</i></td></tr>
<tr><th id="4">4</th><td><i>//</i></td></tr>
<tr><th id="5">5</th><td><i>// This file is distributed under the University of Illinois Open Source</i></td></tr>
<tr><th id="6">6</th><td><i>// License. See LICENSE.TXT for details.</i></td></tr>
<tr><th id="7">7</th><td><i>//</i></td></tr>
<tr><th id="8">8</th><td><i>//===----------------------------------------------------------------------===//</i></td></tr>
<tr><th id="9">9</th><td><i>//</i></td></tr>
<tr><th id="10">10</th><td><i>// This file implements utilities for interfacing with tensorflow C APIs.</i></td></tr>
<tr><th id="11">11</th><td><i>//</i></td></tr>
<tr><th id="12">12</th><td><i>//===----------------------------------------------------------------------===//</i></td></tr>
<tr><th id="13">13</th><td><u>#include <a href="../../../build/include/llvm/Config/config.h.html">"llvm/Config/config.h"</a></u></td></tr>
<tr><th id="14">14</th><td><u>#<span data-ppcond="14">if</span> defined(<span class="macro" data-ref="_M/LLVM_HAVE_TF_API">LLVM_HAVE_TF_API</span>)</u></td></tr>
<tr><th id="15">15</th><td></td></tr>
<tr><th id="16">16</th><td><u>#include "llvm/ADT/Twine.h"</u></td></tr>
<tr><th id="17">17</th><td><u>#include "llvm/Analysis/Utils/TFUtils.h"</u></td></tr>
<tr><th id="18">18</th><td><u>#include "llvm/Support/Debug.h"</u></td></tr>
<tr><th id="19">19</th><td><u>#include "llvm/Support/JSON.h"</u></td></tr>
<tr><th id="20">20</th><td><u>#include "llvm/Support/ManagedStatic.h"</u></td></tr>
<tr><th id="21">21</th><td><u>#include "llvm/Support/MemoryBuffer.h"</u></td></tr>
<tr><th id="22">22</th><td><u>#include "llvm/Support/Path.h"</u></td></tr>
<tr><th id="23">23</th><td><u>#include "llvm/Support/raw_ostream.h"</u></td></tr>
<tr><th id="24">24</th><td></td></tr>
<tr><th id="25">25</th><td><u>#include "tensorflow/c/c_api.h"</u></td></tr>
<tr><th id="26">26</th><td><u>#include "tensorflow/c/c_api_experimental.h"</u></td></tr>
<tr><th id="27">27</th><td></td></tr>
<tr><th id="28">28</th><td><u>#include &lt;cassert&gt;</u></td></tr>
<tr><th id="29">29</th><td><u>#include &lt;numeric&gt;</u></td></tr>
<tr><th id="30">30</th><td></td></tr>
<tr><th id="31">31</th><td><b>using</b> <b>namespace</b> llvm;</td></tr>
<tr><th id="32">32</th><td></td></tr>
<tr><th id="33">33</th><td><b>namespace</b> {</td></tr>
<tr><th id="34">34</th><td></td></tr>
<tr><th id="35">35</th><td><b>using</b> TFGraphPtr = std::unique_ptr&lt;TF_Graph, <b>decltype</b>(&amp;TF_DeleteGraph)&gt;;</td></tr>
<tr><th id="36">36</th><td><b>using</b> TFSessionOptionsPtr =</td></tr>
<tr><th id="37">37</th><td>    std::unique_ptr&lt;TF_SessionOptions, <b>decltype</b>(&amp;TF_DeleteSessionOptions)&gt;;</td></tr>
<tr><th id="38">38</th><td><b>using</b> TFStatusPtr = std::unique_ptr&lt;TF_Status, <b>decltype</b>(&amp;TF_DeleteStatus)&gt;;</td></tr>
<tr><th id="39">39</th><td></td></tr>
<tr><th id="40">40</th><td><b>struct</b> TFInitializer {</td></tr>
<tr><th id="41">41</th><td>  TFInitializer() {</td></tr>
<tr><th id="42">42</th><td>    assert(!IsInitialized &amp;&amp; <q>"TFInitialized should be called only once"</q>);</td></tr>
<tr><th id="43">43</th><td>    <em>int</em> Argc = <var>1</var>;</td></tr>
<tr><th id="44">44</th><td>    <em>const</em> <em>char</em> *Name = <q>""</q>;</td></tr>
<tr><th id="45">45</th><td>    <em>const</em> <em>char</em> **NamePtr = &amp;Name;</td></tr>
<tr><th id="46">46</th><td>    TF_InitMain(Name, &amp;Argc, <b>const_cast</b>&lt;<em>char</em> ***&gt;(&amp;NamePtr));</td></tr>
<tr><th id="47">47</th><td>    IsInitialized = <b>true</b>;</td></tr>
<tr><th id="48">48</th><td>  }</td></tr>
<tr><th id="49">49</th><td>  <em>bool</em> IsInitialized = <b>false</b>;</td></tr>
<tr><th id="50">50</th><td>};</td></tr>
<tr><th id="51">51</th><td></td></tr>
<tr><th id="52">52</th><td>llvm::ManagedStatic&lt;TFInitializer&gt; TFLibInitializer;</td></tr>
<tr><th id="53">53</th><td></td></tr>
<tr><th id="54">54</th><td><em>bool</em> ensureInitTF() { <b>return</b> TFLibInitializer-&gt;IsInitialized; }</td></tr>
<tr><th id="55">55</th><td></td></tr>
<tr><th id="56">56</th><td>TFGraphPtr createTFGraph() {</td></tr>
<tr><th id="57">57</th><td>  <b>return</b> TFGraphPtr(TF_NewGraph(), &amp;TF_DeleteGraph);</td></tr>
<tr><th id="58">58</th><td>}</td></tr>
<tr><th id="59">59</th><td></td></tr>
<tr><th id="60">60</th><td>TFStatusPtr createTFStatus() {</td></tr>
<tr><th id="61">61</th><td>  <b>return</b> TFStatusPtr(TF_NewStatus(), &amp;TF_DeleteStatus);</td></tr>
<tr><th id="62">62</th><td>}</td></tr>
<tr><th id="63">63</th><td></td></tr>
<tr><th id="64">64</th><td>TFSessionOptionsPtr createTFSessionOptions() {</td></tr>
<tr><th id="65">65</th><td>  <b>return</b> TFSessionOptionsPtr(TF_NewSessionOptions(), &amp;TF_DeleteSessionOptions);</td></tr>
<tr><th id="66">66</th><td>}</td></tr>
<tr><th id="67">67</th><td></td></tr>
<tr><th id="68">68</th><td><i class="doc">/// Write the values of one tensor as a list.</i></td></tr>
<tr><th id="69">69</th><td><b>template</b> &lt;<b>typename</b> T&gt;</td></tr>
<tr><th id="70">70</th><td><em>void</em> writeTensorValues(raw_ostream &amp;OutFile, <em>const</em> <em>char</em> *TensorData,</td></tr>
<tr><th id="71">71</th><td>                       size_t ElemCount) {</td></tr>
<tr><th id="72">72</th><td>  OutFile &lt;&lt; <q>"["</q>;</td></tr>
<tr><th id="73">73</th><td>  <em>const</em> T *TypedData = <b>reinterpret_cast</b>&lt;<em>const</em> T *&gt;(TensorData);</td></tr>
<tr><th id="74">74</th><td>  <b>for</b> (size_t I = <var>0</var>; I &lt; ElemCount; ++I) {</td></tr>
<tr><th id="75">75</th><td>    <b>if</b> (I &gt; <var>0</var>)</td></tr>
<tr><th id="76">76</th><td>      OutFile &lt;&lt; <q>", "</q>;</td></tr>
<tr><th id="77">77</th><td>    OutFile &lt;&lt; TypedData[I];</td></tr>
<tr><th id="78">78</th><td>  }</td></tr>
<tr><th id="79">79</th><td>  OutFile &lt;&lt; <q>"]"</q>;</td></tr>
<tr><th id="80">80</th><td>}</td></tr>
<tr><th id="81">81</th><td></td></tr>
<tr><th id="82">82</th><td><i class="doc">/// Write a list of tensors as a sequence of TensorFlow FeatureList protobufs.</i></td></tr>
<tr><th id="83">83</th><td><i class="doc">/// The tensors are assumed to be stored contiguously, in row-major format,</i></td></tr>
<tr><th id="84">84</th><td><i class="doc">/// in the TensorData buffer. Each tensor has the shape given by Spec. The</i></td></tr>
<tr><th id="85">85</th><td><i class="doc">/// feature name in the output is either the provided LoggingName, if</i></td></tr>
<tr><th id="86">86</th><td><i class="doc">/// specified, otherwise it's the name of the tensor (as given by Spec).</i></td></tr>
<tr><th id="87">87</th><td><em>void</em> writeRawTensorsAsFeatureLists(raw_ostream &amp;OutFile,</td></tr>
<tr><th id="88">88</th><td>                                   <em>const</em> LoggedFeatureSpec &amp;LoggedSpec,</td></tr>
<tr><th id="89">89</th><td>                                   <em>const</em> <em>char</em> *TensorData, size_t TensorCount,</td></tr>
<tr><th id="90">90</th><td>                                   <em>bool</em> FinalReward = <b>false</b>) {</td></tr>
<tr><th id="91">91</th><td>  <em>const</em> <em>char</em> *FieldName = <q>"&lt;invalid&gt;"</q>;</td></tr>
<tr><th id="92">92</th><td>  std::function&lt;<em>void</em>(<em>const</em> <em>char</em> *)&gt; ValueWriter;</td></tr>
<tr><th id="93">93</th><td>  <em>const</em> <em>auto</em> &amp;Spec = LoggedSpec.Spec;</td></tr>
<tr><th id="94">94</th><td>  <i>// The 'Feature' protobuf only has 3 possible fields: float_list,</i></td></tr>
<tr><th id="95">95</th><td><i>  // int64_list, or bytes_list, so we capture int32 values as int64. We don't</i></td></tr>
<tr><th id="96">96</th><td><i>  // support any other types.</i></td></tr>
<tr><th id="97">97</th><td>  <b>if</b> (Spec.isElementType&lt;int64_t&gt;()) {</td></tr>
<tr><th id="98">98</th><td>    FieldName = <q>"int64_list"</q>;</td></tr>
<tr><th id="99">99</th><td>    ValueWriter = [&amp;](<em>const</em> <em>char</em> *Data) {</td></tr>
<tr><th id="100">100</th><td>      writeTensorValues&lt;int64_t&gt;(OutFile, Data, Spec.getElementCount());</td></tr>
<tr><th id="101">101</th><td>    };</td></tr>
<tr><th id="102">102</th><td>  } <b>else</b> <b>if</b> (Spec.isElementType&lt;int32_t&gt;()) {</td></tr>
<tr><th id="103">103</th><td>    FieldName = <q>"int64_list"</q>;</td></tr>
<tr><th id="104">104</th><td>    ValueWriter = [&amp;](<em>const</em> <em>char</em> *Data) {</td></tr>
<tr><th id="105">105</th><td>      writeTensorValues&lt;int32_t&gt;(OutFile, Data, Spec.getElementCount());</td></tr>
<tr><th id="106">106</th><td>    };</td></tr>
<tr><th id="107">107</th><td></td></tr>
<tr><th id="108">108</th><td>  } <b>else</b> <b>if</b> (Spec.isElementType&lt;<em>float</em>&gt;()) {</td></tr>
<tr><th id="109">109</th><td>    FieldName = <q>"float_list"</q>;</td></tr>
<tr><th id="110">110</th><td>    ValueWriter = [&amp;](<em>const</em> <em>char</em> *Data) {</td></tr>
<tr><th id="111">111</th><td>      writeTensorValues&lt;<em>float</em>&gt;(OutFile, Data, Spec.getElementCount());</td></tr>
<tr><th id="112">112</th><td>    };</td></tr>
<tr><th id="113">113</th><td></td></tr>
<tr><th id="114">114</th><td>  } <b>else</b> {</td></tr>
<tr><th id="115">115</th><td>    llvm_unreachable(<q>"Unsupported tensor type."</q>);</td></tr>
<tr><th id="116">116</th><td>  }</td></tr>
<tr><th id="117">117</th><td></td></tr>
<tr><th id="118">118</th><td>  OutFile &lt;&lt; <q>"  feature_list: {\n"</q>;</td></tr>
<tr><th id="119">119</th><td>  OutFile &lt;&lt; <q>"    key: "</q></td></tr>
<tr><th id="120">120</th><td>          &lt;&lt; <q>"\""</q></td></tr>
<tr><th id="121">121</th><td>          &lt;&lt; (LoggedSpec.LoggingName ? *LoggedSpec.LoggingName : Spec.name())</td></tr>
<tr><th id="122">122</th><td>          &lt;&lt; <q>"\" "</q>;</td></tr>
<tr><th id="123">123</th><td>  OutFile &lt;&lt; <q>"value: {\n"</q>;</td></tr>
<tr><th id="124">124</th><td>  size_t TensorByteSize = Spec.getElementCount() * Spec.getElementByteSize();</td></tr>
<tr><th id="125">125</th><td></td></tr>
<tr><th id="126">126</th><td>  <em>auto</em> WriteFeatureProto = [&amp;](<em>const</em> <em>char</em> *P) {</td></tr>
<tr><th id="127">127</th><td>    OutFile &lt;&lt; <q>"      feature: { "</q> &lt;&lt; FieldName &lt;&lt; <q>": { value: "</q>;</td></tr>
<tr><th id="128">128</th><td>    ValueWriter(P);</td></tr>
<tr><th id="129">129</th><td>    OutFile &lt;&lt; <q>" } }\n"</q>;</td></tr>
<tr><th id="130">130</th><td>  };</td></tr>
<tr><th id="131">131</th><td></td></tr>
<tr><th id="132">132</th><td>  <em>const</em> <em>char</em> *CurrentTensor = TensorData;</td></tr>
<tr><th id="133">133</th><td>  <em>static</em> int64_t Zero = <var>0</var>;</td></tr>
<tr><th id="134">134</th><td>  <i>// Write all but the last value. If this is the final reward, don't increment</i></td></tr>
<tr><th id="135">135</th><td><i>  // the CurrentTensor, and just write 0.</i></td></tr>
<tr><th id="136">136</th><td>  <b>for</b> (size_t I = <var>0</var>; I &lt; TensorCount - <var>1</var>; ++I) {</td></tr>
<tr><th id="137">137</th><td>    <b>if</b> (FinalReward)</td></tr>
<tr><th id="138">138</th><td>      WriteFeatureProto(<b>reinterpret_cast</b>&lt;<em>const</em> <em>char</em> *&gt;(&amp;Zero));</td></tr>
<tr><th id="139">139</th><td>    <b>else</b> {</td></tr>
<tr><th id="140">140</th><td>      WriteFeatureProto(CurrentTensor);</td></tr>
<tr><th id="141">141</th><td>      CurrentTensor += TensorByteSize;</td></tr>
<tr><th id="142">142</th><td>    }</td></tr>
<tr><th id="143">143</th><td>  }</td></tr>
<tr><th id="144">144</th><td></td></tr>
<tr><th id="145">145</th><td>  WriteFeatureProto(CurrentTensor);</td></tr>
<tr><th id="146">146</th><td></td></tr>
<tr><th id="147">147</th><td>  OutFile &lt;&lt; <q>"    }\n"</q>;</td></tr>
<tr><th id="148">148</th><td>  OutFile &lt;&lt; <q>"  }\n"</q>;</td></tr>
<tr><th id="149">149</th><td>}</td></tr>
<tr><th id="150">150</th><td>} <i>// namespace</i></td></tr>
<tr><th id="151">151</th><td></td></tr>
<tr><th id="152">152</th><td><b>namespace</b> llvm {</td></tr>
<tr><th id="153">153</th><td><b>class</b> EvaluationResultImpl {</td></tr>
<tr><th id="154">154</th><td><b>public</b>:</td></tr>
<tr><th id="155">155</th><td>  EvaluationResultImpl(size_t OutputSize)</td></tr>
<tr><th id="156">156</th><td>      : OutputSize(OutputSize), Output(OutputSize){};</td></tr>
<tr><th id="157">157</th><td></td></tr>
<tr><th id="158">158</th><td>  ~EvaluationResultImpl() {</td></tr>
<tr><th id="159">159</th><td>    <b>for</b> (<em>auto</em> *P : Output)</td></tr>
<tr><th id="160">160</th><td>      <b>if</b> (P)</td></tr>
<tr><th id="161">161</th><td>        TF_DeleteTensor(P);</td></tr>
<tr><th id="162">162</th><td>  }</td></tr>
<tr><th id="163">163</th><td></td></tr>
<tr><th id="164">164</th><td>  EvaluationResultImpl(<em>const</em> EvaluationResultImpl &amp;) = <b>delete</b>;</td></tr>
<tr><th id="165">165</th><td>  EvaluationResultImpl(EvaluationResultImpl &amp;&amp;Other) = <b>delete</b>;</td></tr>
<tr><th id="166">166</th><td>  std::vector&lt;TF_Tensor *&gt; &amp;getOutput() { <b>return</b> Output; }</td></tr>
<tr><th id="167">167</th><td></td></tr>
<tr><th id="168">168</th><td><b>private</b>:</td></tr>
<tr><th id="169">169</th><td>  <em>const</em> size_t OutputSize;</td></tr>
<tr><th id="170">170</th><td>  std::vector&lt;TF_Tensor *&gt; Output;</td></tr>
<tr><th id="171">171</th><td>};</td></tr>
<tr><th id="172">172</th><td></td></tr>
<tr><th id="173">173</th><td>size_t TensorSpec::getElementByteSize() <em>const</em> {</td></tr>
<tr><th id="174">174</th><td>  <b>return</b> TF_DataTypeSize(<b>static_cast</b>&lt;TF_DataType&gt;(TypeIndex));</td></tr>
<tr><th id="175">175</th><td>}</td></tr>
<tr><th id="176">176</th><td></td></tr>
<tr><th id="177">177</th><td>TensorSpec::TensorSpec(<em>const</em> std::string &amp;Name, <em>int</em> Port, <em>int</em> TypeIndex,</td></tr>
<tr><th id="178">178</th><td>                       <em>const</em> std::vector&lt;int64_t&gt; &amp;Shape)</td></tr>
<tr><th id="179">179</th><td>    : Name(Name), Port(Port), TypeIndex(TypeIndex), Shape(Shape),</td></tr>
<tr><th id="180">180</th><td>      ElementCount(std::accumulate(Shape.begin(), Shape.end(), <var>1</var>,</td></tr>
<tr><th id="181">181</th><td>                                   std::multiplies&lt;int64_t&gt;())) {}</td></tr>
<tr><th id="182">182</th><td></td></tr>
<tr><th id="183">183</th><td>Optional&lt;TensorSpec&gt; getTensorSpecFromJSON(LLVMContext &amp;Ctx,</td></tr>
<tr><th id="184">184</th><td>                                           <em>const</em> json::Value &amp;Value) {</td></tr>
<tr><th id="185">185</th><td>  <em>auto</em> EmitError = [&amp;](<em>const</em> llvm::Twine &amp;Message) -&gt; Optional&lt;TensorSpec&gt; {</td></tr>
<tr><th id="186">186</th><td>    std::string S;</td></tr>
<tr><th id="187">187</th><td>    llvm::raw_string_ostream OS(S);</td></tr>
<tr><th id="188">188</th><td>    OS &lt;&lt; Value;</td></tr>
<tr><th id="189">189</th><td>    Ctx.emitError(<q>"Unable to parse JSON Value as spec ("</q> + Message + <q>"): "</q> + S);</td></tr>
<tr><th id="190">190</th><td>    <b>return</b> None;</td></tr>
<tr><th id="191">191</th><td>  };</td></tr>
<tr><th id="192">192</th><td>  <i>// FIXME: accept a Path as a parameter, and use it for error reporting.</i></td></tr>
<tr><th id="193">193</th><td>  json::Path::Root Root(<q>"tensor_spec"</q>);</td></tr>
<tr><th id="194">194</th><td>  json::ObjectMapper Mapper(Value, Root);</td></tr>
<tr><th id="195">195</th><td>  <b>if</b> (!Mapper)</td></tr>
<tr><th id="196">196</th><td>    <b>return</b> EmitError(<q>"Value is not a dict"</q>);</td></tr>
<tr><th id="197">197</th><td></td></tr>
<tr><th id="198">198</th><td>  std::string TensorName;</td></tr>
<tr><th id="199">199</th><td>  <em>int</em> TensorPort = -<var>1</var>;</td></tr>
<tr><th id="200">200</th><td>  std::string TensorType;</td></tr>
<tr><th id="201">201</th><td>  std::vector&lt;int64_t&gt; TensorShape;</td></tr>
<tr><th id="202">202</th><td></td></tr>
<tr><th id="203">203</th><td>  <b>if</b> (!Mapper.map&lt;std::string&gt;(<q>"name"</q>, TensorName))</td></tr>
<tr><th id="204">204</th><td>    <b>return</b> EmitError(<q>"'name' property not present or not a string"</q>);</td></tr>
<tr><th id="205">205</th><td>  <b>if</b> (!Mapper.map&lt;std::string&gt;(<q>"type"</q>, TensorType))</td></tr>
<tr><th id="206">206</th><td>    <b>return</b> EmitError(<q>"'type' property not present or not a string"</q>);</td></tr>
<tr><th id="207">207</th><td>  <b>if</b> (!Mapper.map&lt;<em>int</em>&gt;(<q>"port"</q>, TensorPort))</td></tr>
<tr><th id="208">208</th><td>    <b>return</b> EmitError(<q>"'port' property not present or not an int"</q>);</td></tr>
<tr><th id="209">209</th><td>  <b>if</b> (!Mapper.map&lt;std::vector&lt;int64_t&gt;&gt;(<q>"shape"</q>, TensorShape))</td></tr>
<tr><th id="210">210</th><td>    <b>return</b> EmitError(<q>"'shape' property not present or not an int array"</q>);</td></tr>
<tr><th id="211">211</th><td></td></tr>
<tr><th id="212">212</th><td><u>#define PARSE_TYPE(T, E)                                                       \</u></td></tr>
<tr><th id="213">213</th><td><u>  if (TensorType == #T)                                                        \</u></td></tr>
<tr><th id="214">214</th><td><u>    return TensorSpec::createSpec&lt;T&gt;(TensorName, TensorShape, TensorPort);</u></td></tr>
<tr><th id="215">215</th><td>  TFUTILS_SUPPORTED_TYPES(PARSE_TYPE)</td></tr>
<tr><th id="216">216</th><td><u>#undef PARSE_TYPE</u></td></tr>
<tr><th id="217">217</th><td>  <b>return</b> None;</td></tr>
<tr><th id="218">218</th><td>}</td></tr>
<tr><th id="219">219</th><td></td></tr>
<tr><th id="220">220</th><td>Optional&lt;std::vector&lt;LoggedFeatureSpec&gt;&gt;</td></tr>
<tr><th id="221">221</th><td>loadOutputSpecs(LLVMContext &amp;Ctx, StringRef ExpectedDecisionName,</td></tr>
<tr><th id="222">222</th><td>                StringRef ModelPath, StringRef SpecFileOverride) {</td></tr>
<tr><th id="223">223</th><td>  SmallVector&lt;<em>char</em>, <var>128</var>&gt; OutputSpecsPath;</td></tr>
<tr><th id="224">224</th><td>  StringRef FileName = SpecFileOverride;</td></tr>
<tr><th id="225">225</th><td>  <b>if</b> (FileName.empty()) {</td></tr>
<tr><th id="226">226</th><td>    llvm::sys::path::append(OutputSpecsPath, ModelPath, <q>"output_spec.json"</q>);</td></tr>
<tr><th id="227">227</th><td>    FileName = {OutputSpecsPath.data(), OutputSpecsPath.size()};</td></tr>
<tr><th id="228">228</th><td>  }</td></tr>
<tr><th id="229">229</th><td></td></tr>
<tr><th id="230">230</th><td>  <em>auto</em> BufferOrError = MemoryBuffer::getFileOrSTDIN(FileName);</td></tr>
<tr><th id="231">231</th><td>  <b>if</b> (!BufferOrError) {</td></tr>
<tr><th id="232">232</th><td>    Ctx.emitError(<q>"Error opening output specs file: "</q> + FileName + <q>" : "</q> +</td></tr>
<tr><th id="233">233</th><td>                  BufferOrError.getError().message());</td></tr>
<tr><th id="234">234</th><td>    <b>return</b> None;</td></tr>
<tr><th id="235">235</th><td>  }</td></tr>
<tr><th id="236">236</th><td>  <em>auto</em> ParsedJSONValues = json::parse(BufferOrError.get()-&gt;getBuffer());</td></tr>
<tr><th id="237">237</th><td>  <b>if</b> (!ParsedJSONValues) {</td></tr>
<tr><th id="238">238</th><td>    Ctx.emitError(<q>"Could not parse specs file: "</q> + FileName);</td></tr>
<tr><th id="239">239</th><td>    <b>return</b> None;</td></tr>
<tr><th id="240">240</th><td>  }</td></tr>
<tr><th id="241">241</th><td>  <em>auto</em> ValuesArray = ParsedJSONValues-&gt;getAsArray();</td></tr>
<tr><th id="242">242</th><td>  <b>if</b> (!ValuesArray) {</td></tr>
<tr><th id="243">243</th><td>    Ctx.emitError(<q>"Expected an array of {tensor_spec:&lt;TensorSpec&gt;, "</q></td></tr>
<tr><th id="244">244</th><td>                  <q>"logging_name:&lt;name&gt;} dictionaries"</q>);</td></tr>
<tr><th id="245">245</th><td>    <b>return</b> None;</td></tr>
<tr><th id="246">246</th><td>  }</td></tr>
<tr><th id="247">247</th><td>  std::vector&lt;LoggedFeatureSpec&gt; Ret;</td></tr>
<tr><th id="248">248</th><td>  <b>for</b> (<em>const</em> <em>auto</em> &amp;Value : *ValuesArray)</td></tr>
<tr><th id="249">249</th><td>    <b>if</b> (<em>const</em> <em>auto</em> *Obj = Value.getAsObject())</td></tr>
<tr><th id="250">250</th><td>      <b>if</b> (<em>const</em> <em>auto</em> *SpecPart = Obj-&gt;get(<q>"tensor_spec"</q>))</td></tr>
<tr><th id="251">251</th><td>        <b>if</b> (<em>auto</em> TensorSpec = getTensorSpecFromJSON(Ctx, *SpecPart))</td></tr>
<tr><th id="252">252</th><td>          <b>if</b> (<em>auto</em> LoggingName = Obj-&gt;getString(<q>"logging_name"</q>)) {</td></tr>
<tr><th id="253">253</th><td>            <b>if</b> (!TensorSpec-&gt;isElementType&lt;int64_t&gt;() &amp;&amp;</td></tr>
<tr><th id="254">254</th><td>                !TensorSpec-&gt;isElementType&lt;int32_t&gt;() &amp;&amp;</td></tr>
<tr><th id="255">255</th><td>                !TensorSpec-&gt;isElementType&lt;<em>float</em>&gt;()) {</td></tr>
<tr><th id="256">256</th><td>              Ctx.emitError(</td></tr>
<tr><th id="257">257</th><td>                  <q>"Only int64, int32, and float tensors are supported. "</q></td></tr>
<tr><th id="258">258</th><td>                  <q>"Found unsupported type for tensor named "</q> +</td></tr>
<tr><th id="259">259</th><td>                  TensorSpec-&gt;name());</td></tr>
<tr><th id="260">260</th><td>              <b>return</b> None;</td></tr>
<tr><th id="261">261</th><td>            }</td></tr>
<tr><th id="262">262</th><td>            Ret.push_back({*TensorSpec, LoggingName-&gt;str()});</td></tr>
<tr><th id="263">263</th><td>          }</td></tr>
<tr><th id="264">264</th><td></td></tr>
<tr><th id="265">265</th><td>  <b>if</b> (ValuesArray-&gt;size() != Ret.size()) {</td></tr>
<tr><th id="266">266</th><td>    Ctx.emitError(</td></tr>
<tr><th id="267">267</th><td>        <q>"Unable to parse output spec. It should be a json file containing an "</q></td></tr>
<tr><th id="268">268</th><td>        <q>"array of dictionaries. Each dictionary must have a 'tensor_spec' key, "</q></td></tr>
<tr><th id="269">269</th><td>        <q>"with a json object describing a TensorSpec; and a 'logging_name' key, "</q></td></tr>
<tr><th id="270">270</th><td>        <q>"which is a string to use as name when logging this tensor in the "</q></td></tr>
<tr><th id="271">271</th><td>        <q>"training log."</q>);</td></tr>
<tr><th id="272">272</th><td>    <b>return</b> None;</td></tr>
<tr><th id="273">273</th><td>  }</td></tr>
<tr><th id="274">274</th><td>  <b>if</b> (Ret.empty() || *Ret[<var>0</var>].LoggingName != ExpectedDecisionName) {</td></tr>
<tr><th id="275">275</th><td>    Ctx.emitError(<q>"The first output spec must describe the decision tensor, "</q></td></tr>
<tr><th id="276">276</th><td>                  <q>"and must have the logging_name "</q> +</td></tr>
<tr><th id="277">277</th><td>                  StringRef(ExpectedDecisionName));</td></tr>
<tr><th id="278">278</th><td>    <b>return</b> None;</td></tr>
<tr><th id="279">279</th><td>  }</td></tr>
<tr><th id="280">280</th><td>  <b>return</b> Ret;</td></tr>
<tr><th id="281">281</th><td>}</td></tr>
<tr><th id="282">282</th><td></td></tr>
<tr><th id="283">283</th><td><b>class</b> TFModelEvaluatorImpl {</td></tr>
<tr><th id="284">284</th><td><b>public</b>:</td></tr>
<tr><th id="285">285</th><td>  TFModelEvaluatorImpl(StringRef SavedModelPath,</td></tr>
<tr><th id="286">286</th><td>                       <em>const</em> std::vector&lt;TensorSpec&gt; &amp;InputSpecs,</td></tr>
<tr><th id="287">287</th><td>                       function_ref&lt;TensorSpec(size_t)&gt; GetOutputSpecs,</td></tr>
<tr><th id="288">288</th><td>                       size_t OutputSpecsSize, <em>const</em> <em>char</em> *Tags);</td></tr>
<tr><th id="289">289</th><td></td></tr>
<tr><th id="290">290</th><td>  <em>bool</em> isValid() <em>const</em> { <b>return</b> IsValid; }</td></tr>
<tr><th id="291">291</th><td>  size_t OutputSize() <em>const</em> { <b>return</b> OutputFeed.size(); }</td></tr>
<tr><th id="292">292</th><td></td></tr>
<tr><th id="293">293</th><td>  <em>void</em> evaluate(TF_Tensor **Output, TF_Status *Status) {</td></tr>
<tr><th id="294">294</th><td>    TF_SessionRun(Session, <b>nullptr</b>, InputFeed.data(), Input.data(),</td></tr>
<tr><th id="295">295</th><td>                  Input.size(), OutputFeed.data(), Output, OutputFeed.size(),</td></tr>
<tr><th id="296">296</th><td>                  <b>nullptr</b>, <var>0</var>, <b>nullptr</b>, Status);</td></tr>
<tr><th id="297">297</th><td>  }</td></tr>
<tr><th id="298">298</th><td></td></tr>
<tr><th id="299">299</th><td>  <em>void</em> initInput(size_t Index, TF_DataType Type,</td></tr>
<tr><th id="300">300</th><td>                 <em>const</em> std::vector&lt;int64_t&gt; &amp;Dimensions);</td></tr>
<tr><th id="301">301</th><td>  <em>const</em> std::vector&lt;TF_Tensor *&gt; &amp;getInput() <em>const</em> { <b>return</b> Input; }</td></tr>
<tr><th id="302">302</th><td></td></tr>
<tr><th id="303">303</th><td>  ~TFModelEvaluatorImpl();</td></tr>
<tr><th id="304">304</th><td></td></tr>
<tr><th id="305">305</th><td><b>private</b>:</td></tr>
<tr><th id="306">306</th><td>  <i class="doc">/// The objects necessary for carrying out an evaluation of the SavedModel.</i></td></tr>
<tr><th id="307">307</th><td><i class="doc">  /// They are expensive to set up, and we maintain them accross all the</i></td></tr>
<tr><th id="308">308</th><td><i class="doc">  /// evaluations of the model.</i></td></tr>
<tr><th id="309">309</th><td>  TF_Session *Session = <b>nullptr</b>;</td></tr>
<tr><th id="310">310</th><td>  TFGraphPtr Graph;</td></tr>
<tr><th id="311">311</th><td>  TFSessionOptionsPtr Options;</td></tr>
<tr><th id="312">312</th><td></td></tr>
<tr><th id="313">313</th><td>  <i class="doc">/// The specification of the input nodes.</i></td></tr>
<tr><th id="314">314</th><td>  std::vector&lt;TF_Output&gt; InputFeed;</td></tr>
<tr><th id="315">315</th><td></td></tr>
<tr><th id="316">316</th><td>  <i class="doc">/// The input tensors. They must match by index of the corresponding InputFeed</i></td></tr>
<tr><th id="317">317</th><td><i class="doc">  /// value. We set up the tensors once and just mutate theirs scalars before</i></td></tr>
<tr><th id="318">318</th><td><i class="doc">  /// each evaluation. The input tensors keep their value after an evaluation.</i></td></tr>
<tr><th id="319">319</th><td>  std::vector&lt;TF_Tensor *&gt; Input;</td></tr>
<tr><th id="320">320</th><td></td></tr>
<tr><th id="321">321</th><td>  <i class="doc">/// The specification of the output nodes. When evaluating, the tensors in the</i></td></tr>
<tr><th id="322">322</th><td><i class="doc">  /// output tensor vector must match by index the corresponding element in the</i></td></tr>
<tr><th id="323">323</th><td><i class="doc">  /// OutputFeed.</i></td></tr>
<tr><th id="324">324</th><td>  std::vector&lt;TF_Output&gt; OutputFeed;</td></tr>
<tr><th id="325">325</th><td></td></tr>
<tr><th id="326">326</th><td>  <em>void</em> invalidate() { IsValid = <b>false</b>; }</td></tr>
<tr><th id="327">327</th><td></td></tr>
<tr><th id="328">328</th><td>  <em>bool</em> IsValid = <b>true</b>;</td></tr>
<tr><th id="329">329</th><td></td></tr>
<tr><th id="330">330</th><td>  <i class="doc">/// Reusable utility for ensuring we can bind the requested Name to a node in</i></td></tr>
<tr><th id="331">331</th><td><i class="doc">  /// the SavedModel Graph.</i></td></tr>
<tr><th id="332">332</th><td>  <em>bool</em> checkReportAndInvalidate(<em>const</em> TF_Output &amp;Output,</td></tr>
<tr><th id="333">333</th><td>                                <em>const</em> TensorSpec &amp;OutputSpec);</td></tr>
<tr><th id="334">334</th><td>};</td></tr>
<tr><th id="335">335</th><td>} <i>// namespace llvm</i></td></tr>
<tr><th id="336">336</th><td></td></tr>
<tr><th id="337">337</th><td>TFModelEvaluatorImpl::TFModelEvaluatorImpl(</td></tr>
<tr><th id="338">338</th><td>    StringRef SavedModelPath, <em>const</em> std::vector&lt;TensorSpec&gt; &amp;InputSpecs,</td></tr>
<tr><th id="339">339</th><td>    function_ref&lt;TensorSpec(size_t)&gt; GetOutputSpecs, size_t OutputSpecsSize,</td></tr>
<tr><th id="340">340</th><td>    <em>const</em> <em>char</em> *Tags = <q>"serve"</q>)</td></tr>
<tr><th id="341">341</th><td>    : Graph(createTFGraph()), Options(createTFSessionOptions()),</td></tr>
<tr><th id="342">342</th><td>      InputFeed(InputSpecs.size()), Input(InputSpecs.size()),</td></tr>
<tr><th id="343">343</th><td>      OutputFeed(OutputSpecsSize) {</td></tr>
<tr><th id="344">344</th><td>  <b>if</b> (!ensureInitTF()) {</td></tr>
<tr><th id="345">345</th><td>    errs() &lt;&lt; <q>"Tensorflow should have been initialized"</q>;</td></tr>
<tr><th id="346">346</th><td>    <b>return</b>;</td></tr>
<tr><th id="347">347</th><td>  }</td></tr>
<tr><th id="348">348</th><td>  <em>auto</em> Status = createTFStatus();</td></tr>
<tr><th id="349">349</th><td></td></tr>
<tr><th id="350">350</th><td>  Session = TF_LoadSessionFromSavedModel(Options.get(), <b>nullptr</b>,</td></tr>
<tr><th id="351">351</th><td>                                         SavedModelPath.str().c_str(), &amp;Tags, <var>1</var>,</td></tr>
<tr><th id="352">352</th><td>                                         Graph.get(), <b>nullptr</b>, Status.get());</td></tr>
<tr><th id="353">353</th><td>  <b>if</b> (TF_GetCode(Status.get()) != TF_Code::TF_OK) {</td></tr>
<tr><th id="354">354</th><td>    errs() &lt;&lt; TF_Message(Status.get());</td></tr>
<tr><th id="355">355</th><td>    invalidate();</td></tr>
<tr><th id="356">356</th><td>  }</td></tr>
<tr><th id="357">357</th><td>  <b>for</b> (size_t I = <var>0</var>; I &lt; InputSpecs.size(); ++I) {</td></tr>
<tr><th id="358">358</th><td>    <em>auto</em> &amp;InputSpec = InputSpecs[I];</td></tr>
<tr><th id="359">359</th><td>    InputFeed[I] = {</td></tr>
<tr><th id="360">360</th><td>        TF_GraphOperationByName(Graph.get(), (InputSpec.name()).c_str()),</td></tr>
<tr><th id="361">361</th><td>        InputSpec.port()};</td></tr>
<tr><th id="362">362</th><td>    <b>if</b> (!checkReportAndInvalidate(InputFeed[I], InputSpec))</td></tr>
<tr><th id="363">363</th><td>      <b>return</b>;</td></tr>
<tr><th id="364">364</th><td>    initInput(I, <b>static_cast</b>&lt;TF_DataType&gt;(InputSpec.typeIndex()),</td></tr>
<tr><th id="365">365</th><td>              InputSpec.shape());</td></tr>
<tr><th id="366">366</th><td>  }</td></tr>
<tr><th id="367">367</th><td>  <b>for</b> (size_t I = <var>0</var>; I &lt; OutputSpecsSize; ++I) {</td></tr>
<tr><th id="368">368</th><td>    <em>auto</em> OutputSpec = GetOutputSpecs(I);</td></tr>
<tr><th id="369">369</th><td>    OutputFeed[I] = {</td></tr>
<tr><th id="370">370</th><td>        TF_GraphOperationByName(Graph.get(), (OutputSpec.name()).c_str()),</td></tr>
<tr><th id="371">371</th><td>        OutputSpec.port()};</td></tr>
<tr><th id="372">372</th><td>    <b>if</b> (!checkReportAndInvalidate(OutputFeed[I], OutputSpec))</td></tr>
<tr><th id="373">373</th><td>      <b>return</b>;</td></tr>
<tr><th id="374">374</th><td>  }</td></tr>
<tr><th id="375">375</th><td>}</td></tr>
<tr><th id="376">376</th><td></td></tr>
<tr><th id="377">377</th><td>TFModelEvaluator::TFModelEvaluator(</td></tr>
<tr><th id="378">378</th><td>    StringRef SavedModelPath, <em>const</em> std::vector&lt;TensorSpec&gt; &amp;InputSpecs,</td></tr>
<tr><th id="379">379</th><td>    function_ref&lt;TensorSpec(size_t)&gt; GetOutputSpecs, size_t OutputSpecsSize,</td></tr>
<tr><th id="380">380</th><td>    <em>const</em> <em>char</em> *Tags)</td></tr>
<tr><th id="381">381</th><td>    : Impl(<b>new</b> TFModelEvaluatorImpl(SavedModelPath, InputSpecs, GetOutputSpecs,</td></tr>
<tr><th id="382">382</th><td>                                    OutputSpecsSize, Tags)) {</td></tr>
<tr><th id="383">383</th><td>  <b>if</b> (!Impl-&gt;isValid())</td></tr>
<tr><th id="384">384</th><td>    Impl.reset();</td></tr>
<tr><th id="385">385</th><td>}</td></tr>
<tr><th id="386">386</th><td></td></tr>
<tr><th id="387">387</th><td>TFModelEvaluator::TFModelEvaluator(StringRef SavedModelPath,</td></tr>
<tr><th id="388">388</th><td>                                   <em>const</em> std::vector&lt;TensorSpec&gt; &amp;InputSpecs,</td></tr>
<tr><th id="389">389</th><td>                                   <em>const</em> std::vector&lt;TensorSpec&gt; &amp;OutputSpecs,</td></tr>
<tr><th id="390">390</th><td>                                   <em>const</em> <em>char</em> *Tags)</td></tr>
<tr><th id="391">391</th><td>    : TFModelEvaluator(</td></tr>
<tr><th id="392">392</th><td>          SavedModelPath, InputSpecs, [&amp;](size_t I) { <b>return</b> OutputSpecs[I]; },</td></tr>
<tr><th id="393">393</th><td>          OutputSpecs.size(), Tags) {}</td></tr>
<tr><th id="394">394</th><td></td></tr>
<tr><th id="395">395</th><td>TFModelEvaluatorImpl::~TFModelEvaluatorImpl() {</td></tr>
<tr><th id="396">396</th><td>  <b>for</b> (<em>auto</em> *T : Input) {</td></tr>
<tr><th id="397">397</th><td>    TF_DeleteTensor(T);</td></tr>
<tr><th id="398">398</th><td>  }</td></tr>
<tr><th id="399">399</th><td>  <b>if</b> (Session == <b>nullptr</b>)</td></tr>
<tr><th id="400">400</th><td>    <b>return</b>;</td></tr>
<tr><th id="401">401</th><td>  <em>auto</em> Status = createTFStatus();</td></tr>
<tr><th id="402">402</th><td>  TF_DeleteSession(Session, Status.get());</td></tr>
<tr><th id="403">403</th><td>  Session = <b>nullptr</b>;</td></tr>
<tr><th id="404">404</th><td>  <b>if</b> (TF_GetCode(Status.get()) != TF_Code::TF_OK)</td></tr>
<tr><th id="405">405</th><td>    errs() &lt;&lt; <q>"Could not delete TF session"</q>;</td></tr>
<tr><th id="406">406</th><td>}</td></tr>
<tr><th id="407">407</th><td></td></tr>
<tr><th id="408">408</th><td><em>bool</em> TFModelEvaluatorImpl::checkReportAndInvalidate(</td></tr>
<tr><th id="409">409</th><td>    <em>const</em> TF_Output &amp;Output, <em>const</em> TensorSpec &amp;OutputSpec) {</td></tr>
<tr><th id="410">410</th><td>  <b>if</b> (Output.oper)</td></tr>
<tr><th id="411">411</th><td>    <b>return</b> <b>true</b>;</td></tr>
<tr><th id="412">412</th><td>  errs() &lt;&lt; <q>"Could not find TF_Output named: "</q> + OutputSpec.name();</td></tr>
<tr><th id="413">413</th><td>  IsValid = <b>false</b>;</td></tr>
<tr><th id="414">414</th><td>  <b>return</b> IsValid;</td></tr>
<tr><th id="415">415</th><td>}</td></tr>
<tr><th id="416">416</th><td></td></tr>
<tr><th id="417">417</th><td>Optional&lt;TFModelEvaluator::EvaluationResult&gt; TFModelEvaluator::evaluate() {</td></tr>
<tr><th id="418">418</th><td>  <b>if</b> (!isValid())</td></tr>
<tr><th id="419">419</th><td>    <b>return</b> None;</td></tr>
<tr><th id="420">420</th><td>  std::unique_ptr&lt;EvaluationResultImpl&gt; Ret =</td></tr>
<tr><th id="421">421</th><td>      std::make_unique&lt;EvaluationResultImpl&gt;(Impl-&gt;OutputSize());</td></tr>
<tr><th id="422">422</th><td>  <em>auto</em> Status = createTFStatus();</td></tr>
<tr><th id="423">423</th><td>  Impl-&gt;evaluate(Ret-&gt;getOutput().data(), Status.get());</td></tr>
<tr><th id="424">424</th><td>  <b>if</b> (TF_GetCode(Status.get()) != TF_Code::TF_OK) {</td></tr>
<tr><th id="425">425</th><td>    errs() &lt;&lt; TF_Message(Status.get());</td></tr>
<tr><th id="426">426</th><td>    Impl.reset();</td></tr>
<tr><th id="427">427</th><td>    <b>return</b> None;</td></tr>
<tr><th id="428">428</th><td>  }</td></tr>
<tr><th id="429">429</th><td>  <b>return</b> EvaluationResult(std::move(Ret));</td></tr>
<tr><th id="430">430</th><td>}</td></tr>
<tr><th id="431">431</th><td></td></tr>
<tr><th id="432">432</th><td><em>void</em> TFModelEvaluatorImpl::initInput(size_t Index, TF_DataType Type,</td></tr>
<tr><th id="433">433</th><td>                                     <em>const</em> std::vector&lt;int64_t&gt; &amp;Dimensions) {</td></tr>
<tr><th id="434">434</th><td>  int64_t TotalSize = TF_DataTypeSize(Type);</td></tr>
<tr><th id="435">435</th><td>  <b>for</b> (<em>auto</em> &amp;D : Dimensions)</td></tr>
<tr><th id="436">436</th><td>    TotalSize *= D;</td></tr>
<tr><th id="437">437</th><td></td></tr>
<tr><th id="438">438</th><td>  Input[Index] =</td></tr>
<tr><th id="439">439</th><td>      TF_AllocateTensor(Type, Dimensions.data(), Dimensions.size(), TotalSize);</td></tr>
<tr><th id="440">440</th><td>  std::memset(TF_TensorData(Input[Index]), <var>0</var>, TotalSize);</td></tr>
<tr><th id="441">441</th><td>}</td></tr>
<tr><th id="442">442</th><td></td></tr>
<tr><th id="443">443</th><td><em>void</em> *TFModelEvaluator::getUntypedInput(size_t Index) {</td></tr>
<tr><th id="444">444</th><td>  <b>return</b> TF_TensorData(Impl-&gt;getInput()[Index]);</td></tr>
<tr><th id="445">445</th><td>}</td></tr>
<tr><th id="446">446</th><td></td></tr>
<tr><th id="447">447</th><td>TFModelEvaluator::EvaluationResult::EvaluationResult(</td></tr>
<tr><th id="448">448</th><td>    std::unique_ptr&lt;EvaluationResultImpl&gt; Impl)</td></tr>
<tr><th id="449">449</th><td>    : Impl(std::move(Impl)) {}</td></tr>
<tr><th id="450">450</th><td></td></tr>
<tr><th id="451">451</th><td>TFModelEvaluator::EvaluationResult::EvaluationResult(EvaluationResult &amp;&amp;Other)</td></tr>
<tr><th id="452">452</th><td>    : Impl(std::move(Other.Impl)) {}</td></tr>
<tr><th id="453">453</th><td></td></tr>
<tr><th id="454">454</th><td>TFModelEvaluator::EvaluationResult &amp;</td></tr>
<tr><th id="455">455</th><td>TFModelEvaluator::EvaluationResult::<b>operator</b>=(EvaluationResult &amp;&amp;Other) {</td></tr>
<tr><th id="456">456</th><td>  Impl = std::move(Other.Impl);</td></tr>
<tr><th id="457">457</th><td>  <b>return</b> *<b>this</b>;</td></tr>
<tr><th id="458">458</th><td>}</td></tr>
<tr><th id="459">459</th><td></td></tr>
<tr><th id="460">460</th><td><em>void</em> *TFModelEvaluator::EvaluationResult::getUntypedTensorValue(size_t Index) {</td></tr>
<tr><th id="461">461</th><td>  <b>return</b> TF_TensorData(Impl-&gt;getOutput()[Index]);</td></tr>
<tr><th id="462">462</th><td>}</td></tr>
<tr><th id="463">463</th><td></td></tr>
<tr><th id="464">464</th><td><em>const</em> <em>void</em> *</td></tr>
<tr><th id="465">465</th><td>TFModelEvaluator::EvaluationResult::getUntypedTensorValue(size_t Index) <em>const</em> {</td></tr>
<tr><th id="466">466</th><td>  <b>return</b> TF_TensorData(Impl-&gt;getOutput()[Index]);</td></tr>
<tr><th id="467">467</th><td>}</td></tr>
<tr><th id="468">468</th><td></td></tr>
<tr><th id="469">469</th><td><u>#define TFUTILS_GETDATATYPE_IMPL(T, E)                                         \</u></td></tr>
<tr><th id="470">470</th><td><u>  template &lt;&gt; int TensorSpec::getDataType&lt;T&gt;() { return E; }</u></td></tr>
<tr><th id="471">471</th><td></td></tr>
<tr><th id="472">472</th><td>TFUTILS_SUPPORTED_TYPES(TFUTILS_GETDATATYPE_IMPL)</td></tr>
<tr><th id="473">473</th><td></td></tr>
<tr><th id="474">474</th><td><u>#undef TFUTILS_GETDATATYPE_IMPL</u></td></tr>
<tr><th id="475">475</th><td></td></tr>
<tr><th id="476">476</th><td>TFModelEvaluator::EvaluationResult::~EvaluationResult() {}</td></tr>
<tr><th id="477">477</th><td>TFModelEvaluator::~TFModelEvaluator() {}</td></tr>
<tr><th id="478">478</th><td></td></tr>
<tr><th id="479">479</th><td><em>void</em> Logger::print(raw_ostream &amp;OS) {</td></tr>
<tr><th id="480">480</th><td>  <b>if</b> (RawLogData.empty())</td></tr>
<tr><th id="481">481</th><td>    <b>return</b>;</td></tr>
<tr><th id="482">482</th><td>  <b>if</b> (RawLogData[<var>0</var>].empty())</td></tr>
<tr><th id="483">483</th><td>    <b>return</b>;</td></tr>
<tr><th id="484">484</th><td>  size_t Tensor0Size = FeatureSpecs[<var>0</var>].Spec.getElementCount() *</td></tr>
<tr><th id="485">485</th><td>                       FeatureSpecs[<var>0</var>].Spec.getElementByteSize();</td></tr>
<tr><th id="486">486</th><td>  size_t NumberOfRecords = RawLogData[<var>0</var>].size() / Tensor0Size;</td></tr>
<tr><th id="487">487</th><td>  <b>if</b> (NumberOfRecords == <var>0</var>)</td></tr>
<tr><th id="488">488</th><td>    <b>return</b>;</td></tr>
<tr><th id="489">489</th><td>  size_t RewardSize =</td></tr>
<tr><th id="490">490</th><td>      RewardSpec.getElementCount() * RewardSpec.getElementByteSize();</td></tr>
<tr><th id="491">491</th><td>  size_t NumberOfRewards = RawLogData.back().size() / RewardSize;</td></tr>
<tr><th id="492">492</th><td></td></tr>
<tr><th id="493">493</th><td>  OS &lt;&lt; <q>"feature_lists: {\n"</q>;</td></tr>
<tr><th id="494">494</th><td>  <b>for</b> (size_t I = <var>0</var>; I &lt; FeatureSpecs.size(); ++I)</td></tr>
<tr><th id="495">495</th><td>    writeRawTensorsAsFeatureLists(OS, FeatureSpecs[I], RawLogData[I].data(),</td></tr>
<tr><th id="496">496</th><td>                                  NumberOfRecords);</td></tr>
<tr><th id="497">497</th><td></td></tr>
<tr><th id="498">498</th><td>  <b>if</b> (IncludeReward)</td></tr>
<tr><th id="499">499</th><td>    writeRawTensorsAsFeatureLists(OS, {RewardSpec, None},</td></tr>
<tr><th id="500">500</th><td>                                  RawLogData.back().data(), NumberOfRecords,</td></tr>
<tr><th id="501">501</th><td>                                  NumberOfRewards == <var>1</var>);</td></tr>
<tr><th id="502">502</th><td></td></tr>
<tr><th id="503">503</th><td>  OS &lt;&lt; <q>"}\n"</q>;</td></tr>
<tr><th id="504">504</th><td>}</td></tr>
<tr><th id="505">505</th><td><u>#<span data-ppcond="14">endif</span> // defined(LLVM_HAVE_TF_API)</u></td></tr>
<tr><th id="506">506</th><td></td></tr>
</table><hr/><p id='footer'>
Generated on <em>2021-Jul-01</em> from project llvm revision <em>12</em>