<!doctype html>
<html>
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0"><title>TensorDeviceGpu.h source code [halide/build-apps/eigen/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceGpu.h] - Woboq Code Browser</title>
<link rel="stylesheet" href="../../../../../../../.././data/qtcreator.css" title="QtCreator"/>
<link rel="alternate stylesheet" href="../../../../../../../.././data/kdevelop.css" title="KDevelop"/>
<script type="text/javascript" src="../../../../../../../.././data/jquery/jquery.min.js"></script>
<script type="text/javascript" src="../../../../../../../.././data/jquery/jquery-ui.min.js"></script>
<script>var file = 'halide/build-apps/eigen/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceGpu.h'; var root_path = '../../../../../../../..'; var data_path = '../../../../../../../.././data'; var ecma_script_api_version = 2;</script>
<script src='../../../../../../../.././data/codebrowser.js'></script>
</head>
<body><div id='header'><h1 id='breadcrumb'><span>Browse the source code of </span><a href='../../../../../../..'>halide</a>/<a href='../../../../../..'>build-apps</a>/<a href='../../../../..'>eigen</a>/<a href='../../../..'>unsupported</a>/<a href='../../..'>Eigen</a>/<a href='../..'>CXX11</a>/<a href='..'>src</a>/<a href='./'>Tensor</a>/<a href='TensorDeviceGpu.h.html'>TensorDeviceGpu.h</a></h1></div>
<hr/><div id='content'><table class="code">
<tr><th id="1">1</th><td><i>// This file is part of Eigen, a lightweight C++ template library</i></td></tr>
<tr><th id="2">2</th><td><i>// for linear algebra.</i></td></tr>
<tr><th id="3">3</th><td><i>//</i></td></tr>
<tr><th id="4">4</th><td><i>// Copyright (C) 2014 Benoit Steiner &lt;benoit.steiner.goog@gmail.com&gt;</i></td></tr>
<tr><th id="5">5</th><td><i>//</i></td></tr>
<tr><th id="6">6</th><td><i>// This Source Code Form is subject to the terms of the Mozilla</i></td></tr>
<tr><th id="7">7</th><td><i>// Public License v. 2.0. If a copy of the MPL was not distributed</i></td></tr>
<tr><th id="8">8</th><td><i>// with this file, You can obtain one at <a href="http://mozilla.org/MPL/2.0/">http://mozilla.org/MPL/2.0/</a>.</i></td></tr>
<tr><th id="9">9</th><td></td></tr>
<tr><th id="10">10</th><td><u>#<span data-ppcond="10">if</span> defined(<span class="macro" data-ref="_M/EIGEN_USE_GPU">EIGEN_USE_GPU</span>) &amp;&amp; !defined(<span class="macro" data-ref="_M/EIGEN_CXX11_TENSOR_TENSOR_DEVICE_GPU_H">EIGEN_CXX11_TENSOR_TENSOR_DEVICE_GPU_H</span>)</u></td></tr>
<tr><th id="11">11</th><td><u>#define EIGEN_CXX11_TENSOR_TENSOR_DEVICE_GPU_H</u></td></tr>
<tr><th id="12">12</th><td></td></tr>
<tr><th id="13">13</th><td><i>// This header file container defines fo gpu* macros which will resolve to</i></td></tr>
<tr><th id="14">14</th><td><i>// their equivalent hip* or cuda* versions depending on the compiler in use</i></td></tr>
<tr><th id="15">15</th><td><i>// A separate header (included at the end of this file) will undefine all </i></td></tr>
<tr><th id="16">16</th><td><u>#include "TensorGpuHipCudaDefines.h"</u></td></tr>
<tr><th id="17">17</th><td></td></tr>
<tr><th id="18">18</th><td><b>namespace</b> Eigen {</td></tr>
<tr><th id="19">19</th><td></td></tr>
<tr><th id="20">20</th><td><em>static</em> <em>const</em> <em>int</em> kGpuScratchSize = <var>1024</var>;</td></tr>
<tr><th id="21">21</th><td></td></tr>
<tr><th id="22">22</th><td><i>// This defines an interface that GPUDevice can take to use</i></td></tr>
<tr><th id="23">23</th><td><i>// HIP / CUDA streams underneath.</i></td></tr>
<tr><th id="24">24</th><td><b>class</b> StreamInterface {</td></tr>
<tr><th id="25">25</th><td> <b>public</b>:</td></tr>
<tr><th id="26">26</th><td>  <b>virtual</b> ~StreamInterface() {}</td></tr>
<tr><th id="27">27</th><td></td></tr>
<tr><th id="28">28</th><td>  <b>virtual</b> <em>const</em> gpuStream_t&amp; stream() <em>const</em> = <var>0</var>;</td></tr>
<tr><th id="29">29</th><td>  <b>virtual</b> <em>const</em> gpuDeviceProp_t&amp; deviceProperties() <em>const</em> = <var>0</var>;</td></tr>
<tr><th id="30">30</th><td></td></tr>
<tr><th id="31">31</th><td>  <i>// Allocate memory on the actual device where the computation will run</i></td></tr>
<tr><th id="32">32</th><td>  <b>virtual</b> <em>void</em>* allocate(size_t num_bytes) <em>const</em> = <var>0</var>;</td></tr>
<tr><th id="33">33</th><td>  <b>virtual</b> <em>void</em> deallocate(<em>void</em>* buffer) <em>const</em> = <var>0</var>;</td></tr>
<tr><th id="34">34</th><td></td></tr>
<tr><th id="35">35</th><td>  <i>// Return a scratchpad buffer of size 1k</i></td></tr>
<tr><th id="36">36</th><td>  <b>virtual</b> <em>void</em>* scratchpad() <em>const</em> = <var>0</var>;</td></tr>
<tr><th id="37">37</th><td></td></tr>
<tr><th id="38">38</th><td>  <i>// Return a semaphore. The semaphore is initially initialized to 0, and</i></td></tr>
<tr><th id="39">39</th><td><i>  // each kernel using it is responsible for resetting to 0 upon completion</i></td></tr>
<tr><th id="40">40</th><td><i>  // to maintain the invariant that the semaphore is always equal to 0 upon</i></td></tr>
<tr><th id="41">41</th><td><i>  // each kernel start.</i></td></tr>
<tr><th id="42">42</th><td>  <b>virtual</b> <em>unsigned</em> <em>int</em>* semaphore() <em>const</em> = <var>0</var>;</td></tr>
<tr><th id="43">43</th><td>};</td></tr>
<tr><th id="44">44</th><td></td></tr>
<tr><th id="45">45</th><td><em>static</em> gpuDeviceProp_t* m_deviceProperties;</td></tr>
<tr><th id="46">46</th><td><em>static</em> <em>bool</em> m_devicePropInitialized = <b>false</b>;</td></tr>
<tr><th id="47">47</th><td></td></tr>
<tr><th id="48">48</th><td><em>static</em> <em>void</em> initializeDeviceProp() {</td></tr>
<tr><th id="49">49</th><td>  <b>if</b> (!m_devicePropInitialized) {</td></tr>
<tr><th id="50">50</th><td>    <i>// Attempts to ensure proper behavior in the case of multiple threads</i></td></tr>
<tr><th id="51">51</th><td><i>    // calling this function simultaneously. This would be trivial to</i></td></tr>
<tr><th id="52">52</th><td><i>    // implement if we could use std::mutex, but unfortunately mutex don't</i></td></tr>
<tr><th id="53">53</th><td><i>    // compile with nvcc, so we resort to atomics and thread fences instead.</i></td></tr>
<tr><th id="54">54</th><td><i>    // Note that if the caller uses a compiler that doesn't support c++11 we</i></td></tr>
<tr><th id="55">55</th><td><i>    // can't ensure that the initialization is thread safe.</i></td></tr>
<tr><th id="56">56</th><td>    <em>static</em> std::atomic&lt;<em>bool</em>&gt; first(<b>true</b>);</td></tr>
<tr><th id="57">57</th><td>    <b>if</b> (first.exchange(<b>false</b>)) {</td></tr>
<tr><th id="58">58</th><td>      <i>// We're the first thread to reach this point.</i></td></tr>
<tr><th id="59">59</th><td>      <em>int</em> num_devices;</td></tr>
<tr><th id="60">60</th><td>      gpuError_t status = gpuGetDeviceCount(&amp;num_devices);</td></tr>
<tr><th id="61">61</th><td>      <b>if</b> (status != gpuSuccess) {</td></tr>
<tr><th id="62">62</th><td>        std::cerr &lt;&lt; <q>"Failed to get the number of GPU devices: "</q></td></tr>
<tr><th id="63">63</th><td>                  &lt;&lt; gpuGetErrorString(status)</td></tr>
<tr><th id="64">64</th><td>                  &lt;&lt; std::endl;</td></tr>
<tr><th id="65">65</th><td>        gpu_assert(status == gpuSuccess);</td></tr>
<tr><th id="66">66</th><td>      }</td></tr>
<tr><th id="67">67</th><td>      m_deviceProperties = <b>new</b> gpuDeviceProp_t[num_devices];</td></tr>
<tr><th id="68">68</th><td>      <b>for</b> (<em>int</em> i = <var>0</var>; i &lt; num_devices; ++i) {</td></tr>
<tr><th id="69">69</th><td>        status = gpuGetDeviceProperties(&amp;m_deviceProperties[i], i);</td></tr>
<tr><th id="70">70</th><td>        <b>if</b> (status != gpuSuccess) {</td></tr>
<tr><th id="71">71</th><td>          std::cerr &lt;&lt; <q>"Failed to initialize GPU device #"</q></td></tr>
<tr><th id="72">72</th><td>                    &lt;&lt; i</td></tr>
<tr><th id="73">73</th><td>                    &lt;&lt; <q>": "</q></td></tr>
<tr><th id="74">74</th><td>                    &lt;&lt; gpuGetErrorString(status)</td></tr>
<tr><th id="75">75</th><td>                    &lt;&lt; std::endl;</td></tr>
<tr><th id="76">76</th><td>          gpu_assert(status == gpuSuccess);</td></tr>
<tr><th id="77">77</th><td>        }</td></tr>
<tr><th id="78">78</th><td>      }</td></tr>
<tr><th id="79">79</th><td></td></tr>
<tr><th id="80">80</th><td>      std::atomic_thread_fence(std::memory_order_release);</td></tr>
<tr><th id="81">81</th><td>      m_devicePropInitialized = <b>true</b>;</td></tr>
<tr><th id="82">82</th><td>    } <b>else</b> {</td></tr>
<tr><th id="83">83</th><td>      <i>// Wait for the other thread to inititialize the properties.</i></td></tr>
<tr><th id="84">84</th><td>      <b>while</b> (!m_devicePropInitialized) {</td></tr>
<tr><th id="85">85</th><td>        std::atomic_thread_fence(std::memory_order_acquire);</td></tr>
<tr><th id="86">86</th><td>        EIGEN_SLEEP(<var>1000</var>);</td></tr>
<tr><th id="87">87</th><td>      }</td></tr>
<tr><th id="88">88</th><td>    }</td></tr>
<tr><th id="89">89</th><td>  }</td></tr>
<tr><th id="90">90</th><td>}</td></tr>
<tr><th id="91">91</th><td></td></tr>
<tr><th id="92">92</th><td><em>static</em> <em>const</em> gpuStream_t default_stream = gpuStreamDefault;</td></tr>
<tr><th id="93">93</th><td></td></tr>
<tr><th id="94">94</th><td><b>class</b> GpuStreamDevice : <b>public</b> StreamInterface {</td></tr>
<tr><th id="95">95</th><td> <b>public</b>:</td></tr>
<tr><th id="96">96</th><td>  <i>// Use the default stream on the current device</i></td></tr>
<tr><th id="97">97</th><td>  GpuStreamDevice() : stream_(&amp;default_stream), scratch_(NULL), semaphore_(NULL) {</td></tr>
<tr><th id="98">98</th><td>    gpuGetDevice(&amp;device_);</td></tr>
<tr><th id="99">99</th><td>    initializeDeviceProp();</td></tr>
<tr><th id="100">100</th><td>  }</td></tr>
<tr><th id="101">101</th><td>  <i>// Use the default stream on the specified device</i></td></tr>
<tr><th id="102">102</th><td>  GpuStreamDevice(<em>int</em> device) : stream_(&amp;default_stream), device_(device), scratch_(NULL), semaphore_(NULL) {</td></tr>
<tr><th id="103">103</th><td>    initializeDeviceProp();</td></tr>
<tr><th id="104">104</th><td>  }</td></tr>
<tr><th id="105">105</th><td>  <i>// Use the specified stream. Note that it's the</i></td></tr>
<tr><th id="106">106</th><td><i>  // caller responsibility to ensure that the stream can run on</i></td></tr>
<tr><th id="107">107</th><td><i>  // the specified device. If no device is specified the code</i></td></tr>
<tr><th id="108">108</th><td><i>  // assumes that the stream is associated to the current gpu device.</i></td></tr>
<tr><th id="109">109</th><td>  GpuStreamDevice(<em>const</em> gpuStream_t* stream, <em>int</em> device = -<var>1</var>)</td></tr>
<tr><th id="110">110</th><td>      : stream_(stream), device_(device), scratch_(NULL), semaphore_(NULL) {</td></tr>
<tr><th id="111">111</th><td>    <b>if</b> (device &lt; <var>0</var>) {</td></tr>
<tr><th id="112">112</th><td>      gpuGetDevice(&amp;device_);</td></tr>
<tr><th id="113">113</th><td>    } <b>else</b> {</td></tr>
<tr><th id="114">114</th><td>      <em>int</em> num_devices;</td></tr>
<tr><th id="115">115</th><td>      gpuError_t err = gpuGetDeviceCount(&amp;num_devices);</td></tr>
<tr><th id="116">116</th><td>      EIGEN_UNUSED_VARIABLE(err)</td></tr>
<tr><th id="117">117</th><td>      gpu_assert(err == gpuSuccess);</td></tr>
<tr><th id="118">118</th><td>      gpu_assert(device &lt; num_devices);</td></tr>
<tr><th id="119">119</th><td>      device_ = device;</td></tr>
<tr><th id="120">120</th><td>    }</td></tr>
<tr><th id="121">121</th><td>    initializeDeviceProp();</td></tr>
<tr><th id="122">122</th><td>  }</td></tr>
<tr><th id="123">123</th><td></td></tr>
<tr><th id="124">124</th><td>  <b>virtual</b> ~GpuStreamDevice() {</td></tr>
<tr><th id="125">125</th><td>    <b>if</b> (scratch_) {</td></tr>
<tr><th id="126">126</th><td>      deallocate(scratch_);</td></tr>
<tr><th id="127">127</th><td>    }</td></tr>
<tr><th id="128">128</th><td>  }</td></tr>
<tr><th id="129">129</th><td></td></tr>
<tr><th id="130">130</th><td>  <em>const</em> gpuStream_t&amp; stream() <em>const</em> { <b>return</b> *stream_; }</td></tr>
<tr><th id="131">131</th><td>  <em>const</em> gpuDeviceProp_t&amp; deviceProperties() <em>const</em> {</td></tr>
<tr><th id="132">132</th><td>    <b>return</b> m_deviceProperties[device_];</td></tr>
<tr><th id="133">133</th><td>  }</td></tr>
<tr><th id="134">134</th><td>  <b>virtual</b> <em>void</em>* allocate(size_t num_bytes) <em>const</em> {</td></tr>
<tr><th id="135">135</th><td>    gpuError_t err = gpuSetDevice(device_);</td></tr>
<tr><th id="136">136</th><td>    EIGEN_UNUSED_VARIABLE(err)</td></tr>
<tr><th id="137">137</th><td>    gpu_assert(err == gpuSuccess);</td></tr>
<tr><th id="138">138</th><td>    <em>void</em>* result;</td></tr>
<tr><th id="139">139</th><td>    err = gpuMalloc(&amp;result, num_bytes);</td></tr>
<tr><th id="140">140</th><td>    gpu_assert(err == gpuSuccess);</td></tr>
<tr><th id="141">141</th><td>    gpu_assert(result != NULL);</td></tr>
<tr><th id="142">142</th><td>    <b>return</b> result;</td></tr>
<tr><th id="143">143</th><td>  }</td></tr>
<tr><th id="144">144</th><td>  <b>virtual</b> <em>void</em> deallocate(<em>void</em>* buffer) <em>const</em> {</td></tr>
<tr><th id="145">145</th><td>    gpuError_t err = gpuSetDevice(device_);</td></tr>
<tr><th id="146">146</th><td>    EIGEN_UNUSED_VARIABLE(err)</td></tr>
<tr><th id="147">147</th><td>    gpu_assert(err == gpuSuccess);</td></tr>
<tr><th id="148">148</th><td>    gpu_assert(buffer != NULL);</td></tr>
<tr><th id="149">149</th><td>    err = gpuFree(buffer);</td></tr>
<tr><th id="150">150</th><td>    gpu_assert(err == gpuSuccess);</td></tr>
<tr><th id="151">151</th><td>  }</td></tr>
<tr><th id="152">152</th><td></td></tr>
<tr><th id="153">153</th><td>  <b>virtual</b> <em>void</em>* scratchpad() <em>const</em> {</td></tr>
<tr><th id="154">154</th><td>    <b>if</b> (scratch_ == NULL) {</td></tr>
<tr><th id="155">155</th><td>      scratch_ = allocate(kGpuScratchSize + <b>sizeof</b>(<em>unsigned</em> <em>int</em>));</td></tr>
<tr><th id="156">156</th><td>    }</td></tr>
<tr><th id="157">157</th><td>    <b>return</b> scratch_;</td></tr>
<tr><th id="158">158</th><td>  }</td></tr>
<tr><th id="159">159</th><td></td></tr>
<tr><th id="160">160</th><td>  <b>virtual</b> <em>unsigned</em> <em>int</em>* semaphore() <em>const</em> {</td></tr>
<tr><th id="161">161</th><td>    <b>if</b> (semaphore_ == NULL) {</td></tr>
<tr><th id="162">162</th><td>      <em>char</em>* scratch = <b>static_cast</b>&lt;<em>char</em>*&gt;(scratchpad()) + kGpuScratchSize;</td></tr>
<tr><th id="163">163</th><td>      semaphore_ = <b>reinterpret_cast</b>&lt;<em>unsigned</em> <em>int</em>*&gt;(scratch);</td></tr>
<tr><th id="164">164</th><td>      gpuError_t err = gpuMemsetAsync(semaphore_, <var>0</var>, <b>sizeof</b>(<em>unsigned</em> <em>int</em>), *stream_);</td></tr>
<tr><th id="165">165</th><td>      EIGEN_UNUSED_VARIABLE(err)</td></tr>
<tr><th id="166">166</th><td>      gpu_assert(err == gpuSuccess);</td></tr>
<tr><th id="167">167</th><td>    }</td></tr>
<tr><th id="168">168</th><td>    <b>return</b> semaphore_;</td></tr>
<tr><th id="169">169</th><td>  }</td></tr>
<tr><th id="170">170</th><td></td></tr>
<tr><th id="171">171</th><td> <b>private</b>:</td></tr>
<tr><th id="172">172</th><td>  <em>const</em> gpuStream_t* stream_;</td></tr>
<tr><th id="173">173</th><td>  <em>int</em> device_;</td></tr>
<tr><th id="174">174</th><td>  <em>mutable</em> <em>void</em>* scratch_;</td></tr>
<tr><th id="175">175</th><td>  <em>mutable</em> <em>unsigned</em> <em>int</em>* semaphore_;</td></tr>
<tr><th id="176">176</th><td>};</td></tr>
<tr><th id="177">177</th><td></td></tr>
<tr><th id="178">178</th><td><b>struct</b> GpuDevice {</td></tr>
<tr><th id="179">179</th><td>  <i>// The StreamInterface is not owned: the caller is</i></td></tr>
<tr><th id="180">180</th><td><i>  // responsible for its initialization and eventual destruction.</i></td></tr>
<tr><th id="181">181</th><td>  <b>explicit</b> GpuDevice(<em>const</em> StreamInterface* stream) : stream_(stream), max_blocks_(INT_MAX) {</td></tr>
<tr><th id="182">182</th><td>    eigen_assert(stream);</td></tr>
<tr><th id="183">183</th><td>  }</td></tr>
<tr><th id="184">184</th><td>  <b>explicit</b> GpuDevice(<em>const</em> StreamInterface* stream, <em>int</em> num_blocks) : stream_(stream), max_blocks_(num_blocks) {</td></tr>
<tr><th id="185">185</th><td>    eigen_assert(stream);</td></tr>
<tr><th id="186">186</th><td>  }</td></tr>
<tr><th id="187">187</th><td>  <i>// TODO(bsteiner): This is an internal API, we should not expose it.</i></td></tr>
<tr><th id="188">188</th><td>  EIGEN_STRONG_INLINE <em>const</em> gpuStream_t&amp; stream() <em>const</em> {</td></tr>
<tr><th id="189">189</th><td>    <b>return</b> stream_-&gt;stream();</td></tr>
<tr><th id="190">190</th><td>  }</td></tr>
<tr><th id="191">191</th><td></td></tr>
<tr><th id="192">192</th><td>  EIGEN_STRONG_INLINE <em>void</em>* allocate(size_t num_bytes) <em>const</em> {</td></tr>
<tr><th id="193">193</th><td>    <b>return</b> stream_-&gt;allocate(num_bytes);</td></tr>
<tr><th id="194">194</th><td>  }</td></tr>
<tr><th id="195">195</th><td></td></tr>
<tr><th id="196">196</th><td>  EIGEN_STRONG_INLINE <em>void</em> deallocate(<em>void</em>* buffer) <em>const</em> {</td></tr>
<tr><th id="197">197</th><td>    stream_-&gt;deallocate(buffer);</td></tr>
<tr><th id="198">198</th><td>  }</td></tr>
<tr><th id="199">199</th><td></td></tr>
<tr><th id="200">200</th><td>  EIGEN_STRONG_INLINE <em>void</em>* allocate_temp(size_t num_bytes) <em>const</em> {</td></tr>
<tr><th id="201">201</th><td>    <b>return</b> stream_-&gt;allocate(num_bytes);</td></tr>
<tr><th id="202">202</th><td>  }</td></tr>
<tr><th id="203">203</th><td></td></tr>
<tr><th id="204">204</th><td>  EIGEN_STRONG_INLINE <em>void</em> deallocate_temp(<em>void</em>* buffer) <em>const</em> {</td></tr>
<tr><th id="205">205</th><td>    stream_-&gt;deallocate(buffer);</td></tr>
<tr><th id="206">206</th><td>  }</td></tr>
<tr><th id="207">207</th><td></td></tr>
<tr><th id="208">208</th><td>  <b>template</b>&lt;<b>typename</b> Type&gt;</td></tr>
<tr><th id="209">209</th><td>  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Type get(Type data) <em>const</em> { </td></tr>
<tr><th id="210">210</th><td>    <b>return</b> data;</td></tr>
<tr><th id="211">211</th><td>  }</td></tr>
<tr><th id="212">212</th><td></td></tr>
<tr><th id="213">213</th><td>  EIGEN_STRONG_INLINE <em>void</em>* scratchpad() <em>const</em> {</td></tr>
<tr><th id="214">214</th><td>    <b>return</b> stream_-&gt;scratchpad();</td></tr>
<tr><th id="215">215</th><td>  }</td></tr>
<tr><th id="216">216</th><td></td></tr>
<tr><th id="217">217</th><td>  EIGEN_STRONG_INLINE <em>unsigned</em> <em>int</em>* semaphore() <em>const</em> {</td></tr>
<tr><th id="218">218</th><td>    <b>return</b> stream_-&gt;semaphore();</td></tr>
<tr><th id="219">219</th><td>  }</td></tr>
<tr><th id="220">220</th><td></td></tr>
<tr><th id="221">221</th><td>  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE <em>void</em> memcpy(<em>void</em>* dst, <em>const</em> <em>void</em>* src, size_t n) <em>const</em> {</td></tr>
<tr><th id="222">222</th><td><u>#ifndef EIGEN_GPU_COMPILE_PHASE</u></td></tr>
<tr><th id="223">223</th><td>    gpuError_t err = gpuMemcpyAsync(dst, src, n, gpuMemcpyDeviceToDevice,</td></tr>
<tr><th id="224">224</th><td>                                      stream_-&gt;stream());</td></tr>
<tr><th id="225">225</th><td>    EIGEN_UNUSED_VARIABLE(err)</td></tr>
<tr><th id="226">226</th><td>    gpu_assert(err == gpuSuccess);</td></tr>
<tr><th id="227">227</th><td><u>#else</u></td></tr>
<tr><th id="228">228</th><td>    EIGEN_UNUSED_VARIABLE(dst);</td></tr>
<tr><th id="229">229</th><td>    EIGEN_UNUSED_VARIABLE(src);</td></tr>
<tr><th id="230">230</th><td>    EIGEN_UNUSED_VARIABLE(n);</td></tr>
<tr><th id="231">231</th><td>    eigen_assert(<b>false</b> &amp;&amp; <q>"The default device should be used instead to generate kernel code"</q>);</td></tr>
<tr><th id="232">232</th><td><u>#endif</u></td></tr>
<tr><th id="233">233</th><td>  }</td></tr>
<tr><th id="234">234</th><td></td></tr>
<tr><th id="235">235</th><td>  EIGEN_STRONG_INLINE <em>void</em> memcpyHostToDevice(<em>void</em>* dst, <em>const</em> <em>void</em>* src, size_t n) <em>const</em> {</td></tr>
<tr><th id="236">236</th><td>    gpuError_t err =</td></tr>
<tr><th id="237">237</th><td>        gpuMemcpyAsync(dst, src, n, gpuMemcpyHostToDevice, stream_-&gt;stream());</td></tr>
<tr><th id="238">238</th><td>    EIGEN_UNUSED_VARIABLE(err)</td></tr>
<tr><th id="239">239</th><td>    gpu_assert(err == gpuSuccess);</td></tr>
<tr><th id="240">240</th><td>  }</td></tr>
<tr><th id="241">241</th><td></td></tr>
<tr><th id="242">242</th><td>  EIGEN_STRONG_INLINE <em>void</em> memcpyDeviceToHost(<em>void</em>* dst, <em>const</em> <em>void</em>* src, size_t n) <em>const</em> {</td></tr>
<tr><th id="243">243</th><td>    gpuError_t err =</td></tr>
<tr><th id="244">244</th><td>        gpuMemcpyAsync(dst, src, n, gpuMemcpyDeviceToHost, stream_-&gt;stream());</td></tr>
<tr><th id="245">245</th><td>    EIGEN_UNUSED_VARIABLE(err)</td></tr>
<tr><th id="246">246</th><td>    gpu_assert(err == gpuSuccess);</td></tr>
<tr><th id="247">247</th><td>  }</td></tr>
<tr><th id="248">248</th><td></td></tr>
<tr><th id="249">249</th><td>  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE <em>void</em> memset(<em>void</em>* buffer, <em>int</em> c, size_t n) <em>const</em> {</td></tr>
<tr><th id="250">250</th><td><u>#ifndef EIGEN_GPU_COMPILE_PHASE</u></td></tr>
<tr><th id="251">251</th><td>    gpuError_t err = gpuMemsetAsync(buffer, c, n, stream_-&gt;stream());</td></tr>
<tr><th id="252">252</th><td>    EIGEN_UNUSED_VARIABLE(err)</td></tr>
<tr><th id="253">253</th><td>    gpu_assert(err == gpuSuccess);</td></tr>
<tr><th id="254">254</th><td><u>#else</u></td></tr>
<tr><th id="255">255</th><td>  eigen_assert(<b>false</b> &amp;&amp; <q>"The default device should be used instead to generate kernel code"</q>);</td></tr>
<tr><th id="256">256</th><td><u>#endif</u></td></tr>
<tr><th id="257">257</th><td>  }</td></tr>
<tr><th id="258">258</th><td></td></tr>
<tr><th id="259">259</th><td>  EIGEN_STRONG_INLINE size_t numThreads() <em>const</em> {</td></tr>
<tr><th id="260">260</th><td>    <i>// FIXME</i></td></tr>
<tr><th id="261">261</th><td>    <b>return</b> <var>32</var>;</td></tr>
<tr><th id="262">262</th><td>  }</td></tr>
<tr><th id="263">263</th><td></td></tr>
<tr><th id="264">264</th><td>  EIGEN_STRONG_INLINE size_t firstLevelCacheSize() <em>const</em> {</td></tr>
<tr><th id="265">265</th><td>    <i>// FIXME</i></td></tr>
<tr><th id="266">266</th><td>    <b>return</b> <var>48</var>*<var>1024</var>;</td></tr>
<tr><th id="267">267</th><td>  }</td></tr>
<tr><th id="268">268</th><td></td></tr>
<tr><th id="269">269</th><td>  EIGEN_STRONG_INLINE size_t lastLevelCacheSize() <em>const</em> {</td></tr>
<tr><th id="270">270</th><td>    <i>// We won't try to take advantage of the l2 cache for the time being, and</i></td></tr>
<tr><th id="271">271</th><td><i>    // there is no l3 cache on hip/cuda devices.</i></td></tr>
<tr><th id="272">272</th><td>    <b>return</b> firstLevelCacheSize();</td></tr>
<tr><th id="273">273</th><td>  }</td></tr>
<tr><th id="274">274</th><td></td></tr>
<tr><th id="275">275</th><td>  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE <em>void</em> synchronize() <em>const</em> {</td></tr>
<tr><th id="276">276</th><td><u>#ifndef EIGEN_GPU_COMPILE_PHASE</u></td></tr>
<tr><th id="277">277</th><td>    gpuError_t err = gpuStreamSynchronize(stream_-&gt;stream());</td></tr>
<tr><th id="278">278</th><td>    <b>if</b> (err != gpuSuccess) {</td></tr>
<tr><th id="279">279</th><td>      std::cerr &lt;&lt; <q>"Error detected in GPU stream: "</q></td></tr>
<tr><th id="280">280</th><td>                &lt;&lt; gpuGetErrorString(err)</td></tr>
<tr><th id="281">281</th><td>                &lt;&lt; std::endl;</td></tr>
<tr><th id="282">282</th><td>      gpu_assert(err == gpuSuccess);</td></tr>
<tr><th id="283">283</th><td>    }</td></tr>
<tr><th id="284">284</th><td><u>#else</u></td></tr>
<tr><th id="285">285</th><td>    gpu_assert(<b>false</b> &amp;&amp; <q>"The default device should be used instead to generate kernel code"</q>);</td></tr>
<tr><th id="286">286</th><td><u>#endif</u></td></tr>
<tr><th id="287">287</th><td>  }</td></tr>
<tr><th id="288">288</th><td></td></tr>
<tr><th id="289">289</th><td>  EIGEN_STRONG_INLINE <em>int</em> getNumGpuMultiProcessors() <em>const</em> {</td></tr>
<tr><th id="290">290</th><td>    <b>return</b> stream_-&gt;deviceProperties().multiProcessorCount;</td></tr>
<tr><th id="291">291</th><td>  }</td></tr>
<tr><th id="292">292</th><td>  EIGEN_STRONG_INLINE <em>int</em> maxGpuThreadsPerBlock() <em>const</em> {</td></tr>
<tr><th id="293">293</th><td>    <b>return</b> stream_-&gt;deviceProperties().maxThreadsPerBlock;</td></tr>
<tr><th id="294">294</th><td>  }</td></tr>
<tr><th id="295">295</th><td>  EIGEN_STRONG_INLINE <em>int</em> maxGpuThreadsPerMultiProcessor() <em>const</em> {</td></tr>
<tr><th id="296">296</th><td>    <b>return</b> stream_-&gt;deviceProperties().maxThreadsPerMultiProcessor;</td></tr>
<tr><th id="297">297</th><td>  }</td></tr>
<tr><th id="298">298</th><td>  EIGEN_STRONG_INLINE <em>int</em> sharedMemPerBlock() <em>const</em> {</td></tr>
<tr><th id="299">299</th><td>    <b>return</b> stream_-&gt;deviceProperties().sharedMemPerBlock;</td></tr>
<tr><th id="300">300</th><td>  }</td></tr>
<tr><th id="301">301</th><td>  EIGEN_STRONG_INLINE <em>int</em> majorDeviceVersion() <em>const</em> {</td></tr>
<tr><th id="302">302</th><td>    <b>return</b> stream_-&gt;deviceProperties().major;</td></tr>
<tr><th id="303">303</th><td>  }</td></tr>
<tr><th id="304">304</th><td>  EIGEN_STRONG_INLINE <em>int</em> minorDeviceVersion() <em>const</em> {</td></tr>
<tr><th id="305">305</th><td>    <b>return</b> stream_-&gt;deviceProperties().minor;</td></tr>
<tr><th id="306">306</th><td>  }</td></tr>
<tr><th id="307">307</th><td></td></tr>
<tr><th id="308">308</th><td>  EIGEN_STRONG_INLINE <em>int</em> maxBlocks() <em>const</em> {</td></tr>
<tr><th id="309">309</th><td>    <b>return</b> max_blocks_;</td></tr>
<tr><th id="310">310</th><td>  }</td></tr>
<tr><th id="311">311</th><td></td></tr>
<tr><th id="312">312</th><td>  <i>// This function checks if the GPU runtime recorded an error for the</i></td></tr>
<tr><th id="313">313</th><td><i>  // underlying stream device.</i></td></tr>
<tr><th id="314">314</th><td>  <b>inline</b> <em>bool</em> ok() <em>const</em> {</td></tr>
<tr><th id="315">315</th><td><u>#ifdef EIGEN_GPUCC</u></td></tr>
<tr><th id="316">316</th><td>    gpuError_t error = gpuStreamQuery(stream_-&gt;stream());</td></tr>
<tr><th id="317">317</th><td>    <b>return</b> (error == gpuSuccess) || (error == gpuErrorNotReady);</td></tr>
<tr><th id="318">318</th><td><u>#else</u></td></tr>
<tr><th id="319">319</th><td>    <b>return</b> <b>false</b>;</td></tr>
<tr><th id="320">320</th><td><u>#endif</u></td></tr>
<tr><th id="321">321</th><td>  }</td></tr>
<tr><th id="322">322</th><td></td></tr>
<tr><th id="323">323</th><td> <b>private</b>:</td></tr>
<tr><th id="324">324</th><td>  <em>const</em> StreamInterface* stream_;</td></tr>
<tr><th id="325">325</th><td>  <em>int</em> max_blocks_;</td></tr>
<tr><th id="326">326</th><td>};</td></tr>
<tr><th id="327">327</th><td></td></tr>
<tr><th id="328">328</th><td><u>#if defined(EIGEN_HIPCC)</u></td></tr>
<tr><th id="329">329</th><td></td></tr>
<tr><th id="330">330</th><td><u>#define LAUNCH_GPU_KERNEL(kernel, gridsize, blocksize, sharedmem, device, ...)             \</u></td></tr>
<tr><th id="331">331</th><td><u>  hipLaunchKernelGGL(kernel, dim3(gridsize), dim3(blocksize), (sharedmem), (device).stream(), __VA_ARGS__); \</u></td></tr>
<tr><th id="332">332</th><td><u>  gpu_assert(hipGetLastError() == hipSuccess);</u></td></tr>
<tr><th id="333">333</th><td></td></tr>
<tr><th id="334">334</th><td><u>#else</u></td></tr>
<tr><th id="335">335</th><td> </td></tr>
<tr><th id="336">336</th><td><u>#define LAUNCH_GPU_KERNEL(kernel, gridsize, blocksize, sharedmem, device, ...)             \</u></td></tr>
<tr><th id="337">337</th><td><u>  (kernel) &lt;&lt;&lt; (gridsize), (blocksize), (sharedmem), (device).stream() &gt;&gt;&gt; (__VA_ARGS__);   \</u></td></tr>
<tr><th id="338">338</th><td><u>  gpu_assert(cudaGetLastError() == cudaSuccess);</u></td></tr>
<tr><th id="339">339</th><td></td></tr>
<tr><th id="340">340</th><td><u>#endif</u></td></tr>
<tr><th id="341">341</th><td> </td></tr>
<tr><th id="342">342</th><td><i>// FIXME: Should be device and kernel specific.</i></td></tr>
<tr><th id="343">343</th><td><u>#ifdef EIGEN_GPUCC</u></td></tr>
<tr><th id="344">344</th><td><em>static</em> EIGEN_DEVICE_FUNC <b>inline</b> <em>void</em> setGpuSharedMemConfig(gpuSharedMemConfig config) {</td></tr>
<tr><th id="345">345</th><td><u>#ifndef EIGEN_GPU_COMPILE_PHASE</u></td></tr>
<tr><th id="346">346</th><td>  gpuError_t status = gpuDeviceSetSharedMemConfig(config);</td></tr>
<tr><th id="347">347</th><td>  EIGEN_UNUSED_VARIABLE(status)</td></tr>
<tr><th id="348">348</th><td>  gpu_assert(status == gpuSuccess);</td></tr>
<tr><th id="349">349</th><td><u>#else</u></td></tr>
<tr><th id="350">350</th><td>  EIGEN_UNUSED_VARIABLE(config)</td></tr>
<tr><th id="351">351</th><td><u>#endif</u></td></tr>
<tr><th id="352">352</th><td>}</td></tr>
<tr><th id="353">353</th><td><u>#endif</u></td></tr>
<tr><th id="354">354</th><td></td></tr>
<tr><th id="355">355</th><td>}  <i>// end namespace Eigen</i></td></tr>
<tr><th id="356">356</th><td></td></tr>
<tr><th id="357">357</th><td><i>// undefine all the gpu* macros we defined at the beginning of the file</i></td></tr>
<tr><th id="358">358</th><td><u>#include "TensorGpuHipCudaUndefines.h"</u></td></tr>
<tr><th id="359">359</th><td></td></tr>
<tr><th id="360">360</th><td><u>#<span data-ppcond="10">endif</span>  // EIGEN_CXX11_TENSOR_TENSOR_DEVICE_GPU_H</u></td></tr>
<tr><th id="361">361</th><td></td></tr>
</table><hr/><p id='footer'>
Generated while processing <a href='../../../../../../_deps/tflite-src/tensorflow/lite/kernels/activations.cc.html'>halide/build-apps/_deps/tflite-src/tensorflow/lite/kernels/activations.cc</a><br/>Generated on <em>2021-Aug-05</em> from project halide revision <em>v12.0.1</em>