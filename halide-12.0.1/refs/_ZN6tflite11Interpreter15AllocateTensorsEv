<dec f='halide/build-apps/_deps/tflite-src/tensorflow/lite/interpreter.h' l='432' type='TfLiteStatus tflite::Interpreter::AllocateTensors()'/>
<use f='halide/build-apps/_deps/tflite-src/tensorflow/lite/c/c_api.cc' l='164' u='c' c='TfLiteInterpreterAllocateTensors'/>
<doc f='halide/build-apps/_deps/tflite-src/tensorflow/lite/interpreter.h' l='426'>// Update allocations for all tensors. This will redim dependent tensors
  // using the input tensor dimensionality as given. This is relatively
  // expensive. This *must be* called after the interpreter has been created
  // and before running inference (and accessing tensor buffers), and *must be*
  // called again if (and only if) an input tensor is resized. Returns status of
  // success or failure.</doc>
<use f='halide/build-apps/_deps/tflite-src/tensorflow/lite/examples/label_image/bitmap_helpers_impl.h' l='67' u='c' c='_ZN6tflite11label_image6resizeEPT_PhiiiiiiPNS0_8SettingsE'/>
<use f='halide/build-apps/_deps/tflite-src/tensorflow/lite/examples/label_image/label_image.cc' l='313' u='c' c='_ZN6tflite11label_image12RunInferenceEPNS0_8SettingsERKNS0_17DelegateProvidersE'/>
<def f='halide/build-apps/_deps/tflite-src/tensorflow/lite/interpreter.cc' l='181' ll='236' type='TfLiteStatus tflite::Interpreter::AllocateTensors()'/>
<use f='halide/build-apps/_deps/tflite-src/tensorflow/lite/python/interpreter_wrapper/interpreter_wrapper.cc' l='244' u='c' c='_ZN6tflite19interpreter_wrapper18InterpreterWrapper15AllocateTensorsEv'/>
<use f='halide/build-apps/_deps/tflite-src/tensorflow/lite/tools/benchmark/benchmark_tflite_model.cc' l='779' u='c' c='_ZN6tflite9benchmark20BenchmarkTfLiteModel4InitEv'/>
