<def f='halide/build-apps/_deps/tflite-src/tensorflow/lite/kernels/internal/optimized/depthwiseconv_float.h' l='900' ll='1109' type='void tflite::optimized_ops::DepthwiseConvImpl(const tflite::DepthwiseParams &amp; params, const tflite::RuntimeShape &amp; input_shape, const float * input_data, const tflite::RuntimeShape &amp; filter_shape, const float * filter_data, const tflite::RuntimeShape &amp; bias_shape, const float * bias_data, const tflite::RuntimeShape &amp; output_shape, float * output_data, const tflite::CpuFlags &amp; , int thread_start, int thread_end, int thread_dim)'/>
<doc f='halide/build-apps/_deps/tflite-src/tensorflow/lite/kernels/internal/optimized/depthwiseconv_float.h' l='891'>// DepthwiseConv can run with multi threads on the dim specified by thread_dim.
// Each thread processes output elements on dim, thread_dim, in the range of
// [thread_start, thread_end).
// For example, assume thread_start = 2, thread_end = 6, and thread_dim = 1, it
// means that it will calculate DepthwiseConv for output_data[:, 2:5, :, :].
//
// The cpu_flags is currently unused. This
// parameter is included so that the signature matches that required by a
// templated function. Other versions, such as quantized, need this parameter.</doc>
