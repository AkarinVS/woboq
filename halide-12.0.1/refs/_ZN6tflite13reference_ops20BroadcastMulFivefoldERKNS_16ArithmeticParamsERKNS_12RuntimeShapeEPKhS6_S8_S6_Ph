<def f='halide/build-apps/_deps/tflite-src/tensorflow/lite/kernels/internal/reference/reference_ops.h' l='167' ll='217' type='void tflite::reference_ops::BroadcastMulFivefold(const tflite::ArithmeticParams &amp; unswitched_params, const tflite::RuntimeShape &amp; unswitched_input1_shape, const uint8 * unswitched_input1_data, const tflite::RuntimeShape &amp; unswitched_input2_shape, const uint8 * unswitched_input2_data, const tflite::RuntimeShape &amp; output_shape, uint8 * output_data)'/>
<doc f='halide/build-apps/_deps/tflite-src/tensorflow/lite/kernels/internal/reference/reference_ops.h' l='163'>// TODO(jiawen): We can implement BroadcastMul on buffers of arbitrary
// dimensionality if the runtime code does a single loop over one dimension
// that handles broadcasting as the base case. The code generator would then
// generate max(D1, D2) nested for loops.</doc>
