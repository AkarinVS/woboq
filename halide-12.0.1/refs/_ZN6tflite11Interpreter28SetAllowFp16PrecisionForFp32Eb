<dec f='halide/build-apps/_deps/tflite-src/tensorflow/lite/interpreter.h' l='456' type='void tflite::Interpreter::SetAllowFp16PrecisionForFp32(bool allow)'/>
<doc f='halide/build-apps/_deps/tflite-src/tensorflow/lite/interpreter.h' l='449'>/// Allow float16 precision for FP32 calculation when possible.
  /// Default: not allow.
  ///
  /// WARNING: This API is deprecated: prefer controlling this via delegate
  /// options, e.g. `tflite::StatefulNnApiDelegate::Options::allow_fp16&apos; or
  /// `TfLiteGpuDelegateOptionsV2::is_precision_loss_allowed`.
  /// This method will be removed in a future release.</doc>
<use f='halide/build-apps/_deps/tflite-src/tensorflow/lite/examples/label_image/label_image.cc' l='262' u='c' c='_ZN6tflite11label_image12RunInferenceEPNS0_8SettingsERKNS0_17DelegateProvidersE'/>
<def f='halide/build-apps/_deps/tflite-src/tensorflow/lite/interpreter.cc' l='370' ll='374' type='void tflite::Interpreter::SetAllowFp16PrecisionForFp32(bool allow)'/>
<use f='halide/build-apps/_deps/tflite-src/tensorflow/lite/tools/benchmark/benchmark_tflite_model.cc' l='676' u='c' c='_ZN6tflite9benchmark20BenchmarkTfLiteModel4InitEv'/>
