<def f='halide/build-apps/_deps/tflite-src/tensorflow/lite/kernels/internal/optimized/sparse_ops/fully_connected.h' l='164' ll='202' type='void tflite::optimized_ops::FullyConnectedSparseWeight1x4(const TfLiteSparsity &amp; sparsity, const tflite::FullyConnectedParams &amp; params, const tflite::RuntimeShape &amp; input_shape, const float * input_data, const tflite::RuntimeShape &amp; weights_shape, const float * weights_data, const tflite::RuntimeShape &amp; bias_shape, const float * bias_data, const tflite::RuntimeShape &amp; output_shape, float * output_data, tflite::CpuBackendContext * cpu_backend_context)'/>
<use f='halide/build-apps/_deps/tflite-src/tensorflow/lite/kernels/fully_connected.cc' l='933' u='c' c='_ZN6tflite3ops7builtin15fully_connected9EvalFloatEP13TfLiteContextP10TfLiteNodeP26TfLiteFullyConnectedParamsPNS2_6OpDataEPK12TfLiteTensorSD_SD_PSB_'/>
<doc f='halide/build-apps/_deps/tflite-src/tensorflow/lite/kernels/internal/optimized/sparse_ops/fully_connected.h' l='160'>// The multi-threaded kernel slices the workload along the batch dimension. If
// there&apos;s not enough batches of data, the number of threads used is equal to
// the batch size. We can improve this later with slicing along the row
// dimension of the weight.</doc>
