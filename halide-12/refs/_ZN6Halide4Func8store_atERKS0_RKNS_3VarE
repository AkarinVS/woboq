<dec f='halide/halide-install/include/Halide.h' l='18224' type='Halide::Func &amp; Halide::Func::store_at(const Halide::Func &amp; f, const Halide::Var &amp; var)'/>
<use f='halide/apps/bgu/bgu_generator.cpp' l='579' u='c' c='_ZN12_GLOBAL__N_13BGU8generateEv'/>
<doc f='halide/halide-install/include/Halide.h' l='18131'>/** Allocate storage for this function within f&apos;s loop over
     * var. Scheduling storage is optional, and can be used to
     * separate the loop level at which storage occurs from the loop
     * level at which computation occurs to trade off between locality
     * and redundant work. This can open the door for two types of
     * optimization.
     *
     * Consider again the pipeline from \ref Func::compute_at :
     \code
     Func f, g;
     Var x, y;
     g(x, y) = x*y;
     f(x, y) = g(x, y) + g(x+1, y) + g(x, y+1) + g(x+1, y+1);
     \endcode
     *
     * If we schedule it like so:
     *
     \code
     g.compute_at(f, x).store_at(f, y);
     \endcode
     *
     * Then the computation of g takes place within the loop over x,
     * but the storage takes place within the loop over y:
     *
     \code
     int f[height][width];
     for (int y = 0; y &lt; height; y++) {
         int g[2][width+1];
         for (int x = 0; x &lt; width; x++) {
             g[0][x] = x*y;
             g[0][x+1] = (x+1)*y;
             g[1][x] = x*(y+1);
             g[1][x+1] = (x+1)*(y+1);
             f[y][x] = g[0][x] + g[1][x] + g[0][x+1] + g[1][x+1];
         }
     }
     \endcode
     *
     * Provided the for loop over x is serial, halide then
     * automatically performs the following sliding window
     * optimization:
     *
     \code
     int f[height][width];
     for (int y = 0; y &lt; height; y++) {
         int g[2][width+1];
         for (int x = 0; x &lt; width; x++) {
             if (x == 0) {
                 g[0][x] = x*y;
                 g[1][x] = x*(y+1);
             }
             g[0][x+1] = (x+1)*y;
             g[1][x+1] = (x+1)*(y+1);
             f[y][x] = g[0][x] + g[1][x] + g[0][x+1] + g[1][x+1];
         }
     }
     \endcode
     *
     * Two of the assignments to g only need to be done when x is
     * zero. The rest of the time, those sites have already been
     * filled in by a previous iteration. This version has the
     * locality of compute_at(f, x), but allocates more memory and
     * does much less redundant work.
     *
     * Halide then further optimizes this pipeline like so:
     *
     \code
     int f[height][width];
     for (int y = 0; y &lt; height; y++) {
         int g[2][2];
         for (int x = 0; x &lt; width; x++) {
             if (x == 0) {
                 g[0][0] = x*y;
                 g[1][0] = x*(y+1);
             }
             g[0][(x+1)%2] = (x+1)*y;
             g[1][(x+1)%2] = (x+1)*(y+1);
             f[y][x] = g[0][x%2] + g[1][x%2] + g[0][(x+1)%2] + g[1][(x+1)%2];
         }
     }
     \endcode
     *
     * Halide has detected that it&apos;s possible to use a circular buffer
     * to represent g, and has reduced all accesses to g modulo 2 in
     * the x dimension. This optimization only triggers if the for
     * loop over x is serial, and if halide can statically determine
     * some power of two large enough to cover the range needed. For
     * powers of two, the modulo operator compiles to more efficient
     * bit-masking. This optimization reduces memory usage, and also
     * improves locality by reusing recently-accessed memory instead
     * of pulling new memory into cache.
     *
     */</doc>
<use f='halide/apps/blur/halide_blur_generator.cpp' l='95' u='c' c='_ZN12_GLOBAL__N_110HalideBlur8generateEv'/>
<use f='halide/apps/blur/halide_blur_generator.cpp' l='108' u='c' c='_ZN12_GLOBAL__N_110HalideBlur8generateEv'/>
<use f='halide/apps/camera_pipe/camera_pipe_generator.cpp' l='531' u='c' c='_ZN12_GLOBAL__N_110CameraPipe8generateEv'/>
<use f='halide/apps/camera_pipe/camera_pipe_generator.cpp' l='540' u='c' c='_ZN12_GLOBAL__N_110CameraPipe8generateEv'/>
<use f='halide/apps/camera_pipe/camera_pipe_generator.cpp' l='548' u='c' c='_ZN12_GLOBAL__N_110CameraPipe8generateEv'/>
<use f='halide/apps/harris/harris_generator.cpp' l='114' u='c' c='_ZN12_GLOBAL__N_16Harris8generateEv'/>
<use f='halide/apps/harris/harris_generator.cpp' l='117' u='c' c='_ZN12_GLOBAL__N_16Harris8generateEv'/>
<use f='halide/apps/harris/harris_generator.cpp' l='120' u='c' c='_ZN12_GLOBAL__N_16Harris8generateEv'/>
<use f='halide/apps/interpolate/interpolate_generator.cpp' l='164' u='c' c='_ZN12_GLOBAL__N_111Interpolate8generateEv'/>
<use f='halide/apps/interpolate/interpolate_generator.cpp' l='183' u='c' c='_ZN12_GLOBAL__N_111Interpolate8generateEv'/>
<use f='halide/apps/local_laplacian/local_laplacian_generator.cpp' l='149' u='c' c='_ZN12_GLOBAL__N_114LocalLaplacian8generateEv'/>
<use f='halide/apps/stencil_chain/stencil_chain_generator.cpp' l='139' u='c' c='_ZN12_GLOBAL__N_112StencilChain8generateEv'/>
<use f='halide/apps/unsharp/unsharp_generator.cpp' l='99' u='c' c='_ZN12_GLOBAL__N_17Unsharp8generateEv'/>
<use f='halide/apps/unsharp/unsharp_generator.cpp' l='102' u='c' c='_ZN12_GLOBAL__N_17Unsharp8generateEv'/>
<use f='halide/apps/unsharp/unsharp_generator.cpp' l='105' u='c' c='_ZN12_GLOBAL__N_17Unsharp8generateEv'/>
<dec f='halide/build/include/Halide.h' l='18224' type='Halide::Func &amp; Halide::Func::store_at(const Halide::Func &amp; f, const Halide::Var &amp; var)'/>
<doc f='halide/build/include/Halide.h' l='18131'>/** Allocate storage for this function within f&apos;s loop over
     * var. Scheduling storage is optional, and can be used to
     * separate the loop level at which storage occurs from the loop
     * level at which computation occurs to trade off between locality
     * and redundant work. This can open the door for two types of
     * optimization.
     *
     * Consider again the pipeline from \ref Func::compute_at :
     \code
     Func f, g;
     Var x, y;
     g(x, y) = x*y;
     f(x, y) = g(x, y) + g(x+1, y) + g(x, y+1) + g(x+1, y+1);
     \endcode
     *
     * If we schedule it like so:
     *
     \code
     g.compute_at(f, x).store_at(f, y);
     \endcode
     *
     * Then the computation of g takes place within the loop over x,
     * but the storage takes place within the loop over y:
     *
     \code
     int f[height][width];
     for (int y = 0; y &lt; height; y++) {
         int g[2][width+1];
         for (int x = 0; x &lt; width; x++) {
             g[0][x] = x*y;
             g[0][x+1] = (x+1)*y;
             g[1][x] = x*(y+1);
             g[1][x+1] = (x+1)*(y+1);
             f[y][x] = g[0][x] + g[1][x] + g[0][x+1] + g[1][x+1];
         }
     }
     \endcode
     *
     * Provided the for loop over x is serial, halide then
     * automatically performs the following sliding window
     * optimization:
     *
     \code
     int f[height][width];
     for (int y = 0; y &lt; height; y++) {
         int g[2][width+1];
         for (int x = 0; x &lt; width; x++) {
             if (x == 0) {
                 g[0][x] = x*y;
                 g[1][x] = x*(y+1);
             }
             g[0][x+1] = (x+1)*y;
             g[1][x+1] = (x+1)*(y+1);
             f[y][x] = g[0][x] + g[1][x] + g[0][x+1] + g[1][x+1];
         }
     }
     \endcode
     *
     * Two of the assignments to g only need to be done when x is
     * zero. The rest of the time, those sites have already been
     * filled in by a previous iteration. This version has the
     * locality of compute_at(f, x), but allocates more memory and
     * does much less redundant work.
     *
     * Halide then further optimizes this pipeline like so:
     *
     \code
     int f[height][width];
     for (int y = 0; y &lt; height; y++) {
         int g[2][2];
         for (int x = 0; x &lt; width; x++) {
             if (x == 0) {
                 g[0][0] = x*y;
                 g[1][0] = x*(y+1);
             }
             g[0][(x+1)%2] = (x+1)*y;
             g[1][(x+1)%2] = (x+1)*(y+1);
             f[y][x] = g[0][x%2] + g[1][x%2] + g[0][(x+1)%2] + g[1][(x+1)%2];
         }
     }
     \endcode
     *
     * Halide has detected that it&apos;s possible to use a circular buffer
     * to represent g, and has reduced all accesses to g modulo 2 in
     * the x dimension. This optimization only triggers if the for
     * loop over x is serial, and if halide can statically determine
     * some power of two large enough to cover the range needed. For
     * powers of two, the modulo operator compiles to more efficient
     * bit-masking. This optimization reduces memory usage, and also
     * improves locality by reusing recently-accessed memory instead
     * of pulling new memory into cache.
     *
     */</doc>
<use f='halide/python_bindings/src/PyFunc.cpp' l='202' u='a' c='_ZN6Halide14PythonBindings11define_funcERN8pybind117module_E'/>
<dec f='halide/src/Func.h' l='2344' type='Halide::Func &amp; Halide::Func::store_at(const Halide::Func &amp; f, const Halide::Var &amp; var)'/>
<doc f='halide/src/Func.h' l='2251'>/** Allocate storage for this function within f&apos;s loop over
     * var. Scheduling storage is optional, and can be used to
     * separate the loop level at which storage occurs from the loop
     * level at which computation occurs to trade off between locality
     * and redundant work. This can open the door for two types of
     * optimization.
     *
     * Consider again the pipeline from \ref Func::compute_at :
     \code
     Func f, g;
     Var x, y;
     g(x, y) = x*y;
     f(x, y) = g(x, y) + g(x+1, y) + g(x, y+1) + g(x+1, y+1);
     \endcode
     *
     * If we schedule it like so:
     *
     \code
     g.compute_at(f, x).store_at(f, y);
     \endcode
     *
     * Then the computation of g takes place within the loop over x,
     * but the storage takes place within the loop over y:
     *
     \code
     int f[height][width];
     for (int y = 0; y &lt; height; y++) {
         int g[2][width+1];
         for (int x = 0; x &lt; width; x++) {
             g[0][x] = x*y;
             g[0][x+1] = (x+1)*y;
             g[1][x] = x*(y+1);
             g[1][x+1] = (x+1)*(y+1);
             f[y][x] = g[0][x] + g[1][x] + g[0][x+1] + g[1][x+1];
         }
     }
     \endcode
     *
     * Provided the for loop over x is serial, halide then
     * automatically performs the following sliding window
     * optimization:
     *
     \code
     int f[height][width];
     for (int y = 0; y &lt; height; y++) {
         int g[2][width+1];
         for (int x = 0; x &lt; width; x++) {
             if (x == 0) {
                 g[0][x] = x*y;
                 g[1][x] = x*(y+1);
             }
             g[0][x+1] = (x+1)*y;
             g[1][x+1] = (x+1)*(y+1);
             f[y][x] = g[0][x] + g[1][x] + g[0][x+1] + g[1][x+1];
         }
     }
     \endcode
     *
     * Two of the assignments to g only need to be done when x is
     * zero. The rest of the time, those sites have already been
     * filled in by a previous iteration. This version has the
     * locality of compute_at(f, x), but allocates more memory and
     * does much less redundant work.
     *
     * Halide then further optimizes this pipeline like so:
     *
     \code
     int f[height][width];
     for (int y = 0; y &lt; height; y++) {
         int g[2][2];
         for (int x = 0; x &lt; width; x++) {
             if (x == 0) {
                 g[0][0] = x*y;
                 g[1][0] = x*(y+1);
             }
             g[0][(x+1)%2] = (x+1)*y;
             g[1][(x+1)%2] = (x+1)*(y+1);
             f[y][x] = g[0][x%2] + g[1][x%2] + g[0][(x+1)%2] + g[1][(x+1)%2];
         }
     }
     \endcode
     *
     * Halide has detected that it&apos;s possible to use a circular buffer
     * to represent g, and has reduced all accesses to g modulo 2 in
     * the x dimension. This optimization only triggers if the for
     * loop over x is serial, and if halide can statically determine
     * some power of two large enough to cover the range needed. For
     * powers of two, the modulo operator compiles to more efficient
     * bit-masking. This optimization reduces memory usage, and also
     * improves locality by reusing recently-accessed memory instead
     * of pulling new memory into cache.
     *
     */</doc>
<def f='halide/src/Func.cpp' l='2682' ll='2684' type='Halide::Func &amp; Halide::Func::store_at(const Halide::Func &amp; f, const Halide::Var &amp; var)'/>
<use f='halide/src/autoschedulers/adams2019/cost_model_generator.cpp' l='506' u='c' c='_ZN9CostModel8generateEv'/>
<use f='halide/test/generator/async_parallel_generator.cpp' l='30' u='c' c='_ZN13AsyncParallel8generateEv'/>
<use f='halide/test/generator/async_parallel_generator.cpp' l='31' u='c' c='_ZN13AsyncParallel8generateEv'/>
<use f='halide/test/generator/async_parallel_generator.cpp' l='32' u='c' c='_ZN13AsyncParallel8generateEv'/>
<use f='halide/tutorial/lesson_08_scheduling_2.cpp' l='577' u='c' c='main'/>
<use f='halide/tutorial/lesson_09_update_definitions.cpp' l='784' u='c' c='main'/>
<use f='halide/tutorial/lesson_12_using_the_gpu.cpp' l='100' u='c' c='_ZN10MyPipeline16schedule_for_cpuEv'/>
