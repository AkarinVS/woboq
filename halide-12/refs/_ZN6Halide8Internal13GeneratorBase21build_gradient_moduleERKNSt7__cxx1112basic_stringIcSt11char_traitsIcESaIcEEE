<dec f='halide/halide-install/include/Halide.h' l='26048' type='Halide::Module Halide::Internal::GeneratorBase::build_gradient_module(const std::string &amp; function_name)'/>
<doc f='halide/halide-install/include/Halide.h' l='26034'>/**
     * Build a module that is suitable for using for gradient descent calculation in TensorFlow or PyTorch.
     *
     * Essentially:
     *   - A new Pipeline is synthesized from the current Generator (according to the rules below)
     *   - The new Pipeline is autoscheduled (if autoscheduling is requested, but it would be odd not to do so)
     *   - The Pipeline is compiled to a Module and returned
     *
     * The new Pipeline is adjoint to the original; it has:
     *   - All the same inputs as the original, in the same order
     *   - Followed by one grad-input for each original output
     *   - Followed by one output for each unique pairing of original-output + original-input.
     *     (For the common case of just one original-output, this amounts to being one output for each original-input.)
     */</doc>
<dec f='halide/build/include/Halide.h' l='26048' type='Halide::Module Halide::Internal::GeneratorBase::build_gradient_module(const std::string &amp; function_name)'/>
<doc f='halide/build/include/Halide.h' l='26034'>/**
     * Build a module that is suitable for using for gradient descent calculation in TensorFlow or PyTorch.
     *
     * Essentially:
     *   - A new Pipeline is synthesized from the current Generator (according to the rules below)
     *   - The new Pipeline is autoscheduled (if autoscheduling is requested, but it would be odd not to do so)
     *   - The Pipeline is compiled to a Module and returned
     *
     * The new Pipeline is adjoint to the original; it has:
     *   - All the same inputs as the original, in the same order
     *   - Followed by one grad-input for each original output
     *   - Followed by one output for each unique pairing of original-output + original-input.
     *     (For the common case of just one original-output, this amounts to being one output for each original-input.)
     */</doc>
<dec f='halide/src/Generator.h' l='3114' type='Halide::Module Halide::Internal::GeneratorBase::build_gradient_module(const std::string &amp; function_name)'/>
<use f='halide/src/Generator.cpp' l='1031' u='c' c='_ZN6Halide8Internal26generate_filter_main_innerEiPPcRSo'/>
<def f='halide/src/Generator.cpp' l='1500' ll='1659' type='Halide::Module Halide::Internal::GeneratorBase::build_gradient_module(const std::string &amp; function_name)'/>
<doc f='halide/src/Generator.h' l='3100'>/**
     * Build a module that is suitable for using for gradient descent calculation in TensorFlow or PyTorch.
     *
     * Essentially:
     *   - A new Pipeline is synthesized from the current Generator (according to the rules below)
     *   - The new Pipeline is autoscheduled (if autoscheduling is requested, but it would be odd not to do so)
     *   - The Pipeline is compiled to a Module and returned
     *
     * The new Pipeline is adjoint to the original; it has:
     *   - All the same inputs as the original, in the same order
     *   - Followed by one grad-input for each original output
     *   - Followed by one output for each unique pairing of original-output + original-input.
     *     (For the common case of just one original-output, this amounts to being one output for each original-input.)
     */</doc>
